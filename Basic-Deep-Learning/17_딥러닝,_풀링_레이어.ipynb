{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAjipgGuSJ0fTPNXDKAPLx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunHyeong-data/ML-DL-Study/blob/main/Basic-Deep-Learning/17_%EB%94%A5%EB%9F%AC%EB%8B%9D%2C_%ED%92%80%EB%A7%81_%EB%A0%88%EC%9D%B4%EC%96%B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pooling Layer와 Modern CNN에서의 Spatial Dimension Reduction\n",
        "\n",
        "## 1. Pooling Layer란?\n",
        "\n",
        "고전적인 CNN 아키텍처에서 자주 사용되던 레이어로,  \n",
        "**Spatial Dimension(가로·세로 크기)을 줄이는 역할**을 한다.\n",
        "\n",
        "대표적인 풀링 방식은 다음과 같다.\n",
        "\n",
        "- **Max Pooling**\n",
        "- **Average Pooling**\n",
        "\n",
        "현대적인 CNN에서는 사용 빈도가 줄었지만,  \n",
        "공간 차원을 줄인다는 개념 자체는 매우 중요하다.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Max Pooling의 동작 원리\n",
        "\n",
        "### 예제 1: 간단한 크기 변화\n",
        "- 입력 텐서 크기: `4 × 4`\n",
        "- 커널 사이즈: `2 × 2`\n",
        "- 출력 텐서 크기: `2 × 2`\n",
        "\n",
        "즉, 가로·세로가 각각 절반으로 줄어든다.\n",
        "\n",
        "### 예제 2: 값 선택 방식\n",
        "각 `2 × 2` 영역에서 **최댓값만 선택**하여 출력한다.\n",
        "\n",
        "예를 들어, 입력 값이 다음과 같이 주어졌을 때:\n",
        "\n",
        "```\n",
        "\n",
        "1 3 | 5 7\n",
        "2 4 | 6 8\n",
        "---------\n",
        "\n",
        "1 7 | 3 9\n",
        "2 5 | 4 6\n",
        "\n",
        "```\n",
        "\n",
        "Max Pooling 결과는 각 영역의 최대값만 남는다.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Average Pooling\n",
        "\n",
        "Max Pooling 대신  \n",
        "각 영역의 **평균값을 출력**하는 방식이다.\n",
        "\n",
        "- 정보 손실은 여전히 존재\n",
        "- Max Pooling보다 부드러운 결과를 만든다\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Spatial Dimension 감소 효과\n",
        "\n",
        "- 입력 이미지 크기: `512 × 512`\n",
        "- Kernel size = 2인 Pooling 적용 시:\n",
        "  - 출력 크기: `256 × 256`\n",
        "  - 면적 기준으로는 **1/4 감소**\n",
        "\n",
        "Pooling을 여러 번 반복하면:\n",
        "```\n",
        "\n",
        "512 → 256 → 128 → 64 → 32\n",
        "\n",
        "```\n",
        "\n",
        "아주 빠르게 Spatial Dimension이 줄어든다.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Pooling Layer의 한계\n",
        "\n",
        "모던 CNN에서 잘 사용되지 않는 이유는 다음과 같다.\n",
        "\n",
        "1. **정보 손실이 큼**\n",
        "   - Max Pooling은 선택된 값 외의 정보가 완전히 사라짐\n",
        "\n",
        "2. **학습 가능한 파라미터가 없음**\n",
        "   - Convolution Layer는 weight를 학습\n",
        "   - Pooling Layer는 고정 연산\n",
        "\n",
        "이 때문에 중요한 feature가 버려질 가능성이 있다.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Modern CNN의 대안: Strided Convolution\n",
        "\n",
        "현대 CNN에서는 Pooling 대신  \n",
        "**Convolution Layer의 stride 옵션**을 사용한다.\n",
        "\n",
        "### 장점\n",
        "- Spatial Dimension 감소\n",
        "- 동시에 **학습 가능한 weight 유지**\n",
        "- 정보 손실 최소화\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Global Average Pooling (GAP)\n",
        "\n",
        "### 개념\n",
        "- Feature Extraction의 **마지막 텐서에서**\n",
        "- **각 채널별로 평균을 계산**\n",
        "\n",
        "### 예시\n",
        "- 마지막 Feature Tensor 크기: `128 × 16 × 16`\n",
        "  - 채널 수: 128\n",
        "  - 각 채널의 `16 × 16` 값을 평균\n",
        "\n",
        "결과:\n",
        "- `128`차원의 벡터 생성\n",
        "\n",
        "---\n",
        "\n",
        "## 8. 기존 방식 vs Global Average Pooling\n",
        "\n",
        "### 기존 CNN 구조\n",
        "1. Feature Map (`128 × 16 × 16`)\n",
        "2. Flatten → 약 32,000차원 벡터\n",
        "3. Fully Connected Layer\n",
        "4. Classification\n",
        "\n",
        "➡ 연산량과 파라미터 수가 매우 큼\n",
        "\n",
        "### Global Average Pooling 적용\n",
        "1. Feature Map (`128 × 16 × 16`)\n",
        "2. Channel-wise Average\n",
        "3. `128`차원 벡터\n",
        "4. 바로 Classification\n",
        "\n",
        "➡ **연산량 대폭 감소**\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Global Average Pooling의 장점\n",
        "\n",
        "1. **연산량 감소**\n",
        "2. **과적합 위험 감소**\n",
        "3. **위치 정보 제거**\n",
        "   - Classification 문제에서는 객체 위치가 중요하지 않음\n",
        "   - 위치에 무관한 robust한 분류 가능\n",
        "\n",
        "---\n",
        "\n",
        "## 10. 정리\n",
        "\n",
        "- CNN은 크게 두 부분으로 나뉜다\n",
        "  - Feature Extraction\n",
        "  - Classification\n",
        "\n",
        "- Pooling Layer\n",
        "  - Spatial Dimension을 빠르게 줄임\n",
        "  - 하지만 정보 손실 큼\n",
        "  - 현대 CNN에서는 거의 사용되지 않음\n",
        "\n",
        "- Modern CNN\n",
        "  - Strided Convolution으로 공간 축소\n",
        "  - Global Average Pooling으로 FC Layer 대체\n",
        "\n",
        "---\n",
        "\n",
        "## 다음 내용\n",
        "다음 시간에는 **Normalization Layer**에 대해 다룬다."
      ],
      "metadata": {
        "id": "WpSmJDuIckD-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UQ7rB7wcgqp",
        "outputId": "8f258159-f6ef-4cc0-a659-81c95e3d9e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 4, 4])\n",
            "tensor([[[[ 6.,  8.],\n",
            "          [14., 16.]]]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input_tensor = torch.Tensor([[[[1, 2, 3, 4],\n",
        "                             [5, 6, 7, 8],\n",
        "                             [9, 10, 11, 12],\n",
        "                             [13, 14, 15, 16]]]])\n",
        "print(input_tensor.shape)\n",
        "maxpool_layer = nn.MaxPool2d(kernel_size=2)\n",
        "output_tensor = maxpool_layer(input_tensor)\n",
        "print(output_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avgpool_layer = nn.AvgPool2d(kernel_size=2)\n",
        "output_tensor = avgpool_layer(input_tensor)\n",
        "print(output_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0dUpCyHd-Iz",
        "outputId": "8238e9d9-b8bc-4a26-b453-15a654359b53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 3.5000,  5.5000],\n",
            "          [11.5000, 13.5000]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "my_device = torch.device('cpu')\n",
        "print(my_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9I4-xu9eY3K",
        "outputId": "6ab64c3e-00e4-40c6-ad06-dfea77e3d41b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq7NVtQ3evp3",
        "outputId": "56b8b58f-8d99-4d91-e4a6-864db665383e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ModerGAPCNN(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super().__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "    self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.classifier = nn.Linear(128, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.global_avg_pool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "net = ModerGAPCNN(num_classes=10)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "u1gQEaBsf-bg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 항목          | 이유                |\n",
        "| ----------- | ----------------- |\n",
        "| 공간 크기 ↓     | 계산량 감소, 위치 불변성 증가 |\n",
        "| 채널 수 ↑      | 더 많은 특징 표현 가능     |\n",
        "| stride Conv | 학습 가능한 다운샘플링      |\n"
      ],
      "metadata": {
        "id": "apQAjncPmWHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net.to(my_device)\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    net.train()\n",
        "    for batch_idx, (data, label) in enumerate(trainloader):\n",
        "        data, label = data.to(my_device), label.to(my_device)\n",
        "        scores = net(data)\n",
        "        loss = criterion(scores, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    net.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, label in testloader:\n",
        "            data, label = data.to(my_device), label.to(my_device)\n",
        "            scores = net(data)\n",
        "            loss = criterion(scores, label)\n",
        "            val_loss += loss.item() * data.size(0)\n",
        "\n",
        "            predicted = scores.argmax(dim=1)\n",
        "            correct += predicted.eq(label).sum().item()\n",
        "\n",
        "    val_loss /= len(testloader.dataset)\n",
        "    val_accuracy = 100. * correct / len(testloader.dataset)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "iQFUunznmaVb",
        "outputId": "0920f267-ded7-4755-a7b1-404af9d74afe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Training Loss: 1.4457, Validation Loss: 1.5384, Validation Accuracy: 45.64%\n",
            "Epoch [2/100], Training Loss: 1.2725, Validation Loss: 1.4052, Validation Accuracy: 49.48%\n",
            "Epoch [3/100], Training Loss: 1.2714, Validation Loss: 1.3259, Validation Accuracy: 53.03%\n",
            "Epoch [4/100], Training Loss: 1.4004, Validation Loss: 1.2737, Validation Accuracy: 54.40%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1076457023.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}