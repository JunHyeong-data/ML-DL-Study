{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfBz0CdZa5SU0687Hi2q5Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunHyeong-data/ML-DL-Study/blob/main/Basic-Deep-Learning/15_%EB%94%A5%EB%9F%AC%EB%8B%9D%2C_CNN_Depth_Channel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network에서 Channel과 Architecture 이해\n",
        "\n",
        "## 1. Convolution 연산과 Feature 추출\n",
        "\n",
        "이전 시간에는 컨볼루션(convolution) 연산을 통해 이미지에 커널을 적용하면,  \n",
        "커널의 형태에 따라 서로 다른 특징(feature)이 강조된 출력 이미지가 생성된다는 것을 배웠다.\n",
        "\n",
        "어떤 커널을 사용하느냐에 따라\n",
        "- 엣지가 강조된 이미지가 나올 수도 있고\n",
        "- 가로 또는 세로 방향의 패턴이 강조될 수도 있다.\n",
        "\n",
        "이렇게 생성된 출력 이미지에 다시 컨볼루션 연산을 반복적으로 적용하면,  \n",
        "점점 더 **복잡한 수준의 피처(feature)** 를 추출하는 것이 가능하다.\n",
        "\n",
        "일반적으로 CNN에서\n",
        "- 입력에 가까운 레이어에서는 **저수준 피처(low-level feature)** 가,\n",
        "- 깊은 레이어로 갈수록 **고수준 피처(high-level feature)** 가 추출된다.\n",
        "\n",
        "하지만 실제 CNN을 제대로 이해하기 위해서는  \n",
        "단순한 개념 설명을 넘어서 **네트워크 아키텍처에서 각 블록이 의미하는 바를 바로 해석할 수 있어야 한다.**\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Channel 개념의 중요성\n",
        "\n",
        "CNN 아키텍처를 이해하는 데 있어 가장 중요한 개념 중 하나는 **채널(channel, depth)** 이다.\n",
        "\n",
        "PyTorch에서 `Conv2d` 클래스를 사용할 때,\n",
        "- 첫 번째 인자는 `input channel`\n",
        "- 두 번째 인자는 `output channel`\n",
        "\n",
        "을 의미한다.\n",
        "\n",
        "이 채널 개념을 정확히 이해하지 못하면 CNN 구조를 해석하기 어렵다.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Grayscale 이미지에서의 Convolution\n",
        "\n",
        "먼저 가장 단순한 경우를 살펴본다.\n",
        "\n",
        "- 입력 이미지: 그레이스케일 이미지\n",
        "- 이미지 크기: 4 × 4\n",
        "- 커널 크기: 2 × 2\n",
        "\n",
        "슬라이딩 윈도우 방식으로 컨볼루션을 적용하면,\n",
        "출력 이미지의 가로, 세로 크기는 각각 3이 된다.\n",
        "\n",
        "이 경우 입력 채널이 1개이므로,\n",
        "출력도 기본적으로 **1개의 이미지**가 생성된다.\n",
        "\n",
        "하지만 서로 다른 커널을 여러 개 사용하면,\n",
        "각 커널마다 하나의 출력 이미지가 생성된다.\n",
        "\n",
        "예를 들어,\n",
        "- 커널 개수 = 4개  \n",
        "→ 출력 이미지도 4개 생성\n",
        "\n",
        "이 출력 이미지들을 쌓으면,\n",
        "출력 텐서는 다음과 같은 형태가 된다.\n",
        "\n",
        "- Height: 3\n",
        "- Width: 3\n",
        "- Channel (Depth): 4\n",
        "\n",
        "즉, `(3, 3, 4)` 형태의 텐서가 된다.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Channel을 이미지로 이해하기\n",
        "\n",
        "처음 컴퓨터 비전을 접하면  \n",
        "채널(depth)이 여러 개인 이미지가 직관적으로 이해되지 않을 수 있다.\n",
        "\n",
        "하지만 우리는 이미 매일 채널이 3개인 이미지를 보고 있다.\n",
        "바로 **RGB 이미지**이다.\n",
        "\n",
        "- R 채널\n",
        "- G 채널\n",
        "- B 채널\n",
        "\n",
        "이와 마찬가지로,\n",
        "채널이 4개인 텐서 역시  \n",
        "**채널이 4개인 이미지**라고 이해하면 된다.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Color 이미지에서의 Convolution\n",
        "\n",
        "이제 입력 이미지를 그레이스케일이 아닌 **컬러 이미지(RGB)** 로 바꿔보자.\n",
        "\n",
        "입력 이미지가 3개의 채널을 가지므로,\n",
        "컨볼루션에 사용되는 커널 역시 **3개의 채널**을 가져야 한다.\n",
        "\n",
        "즉, 커널은 3차원 형태를 가진다.\n",
        "\n",
        "이 3차원 커널 하나를 사용해 컨볼루션을 적용하면,\n",
        "- 가로 × 세로 크기의\n",
        "- **채널이 1개인 출력 이미지**\n",
        "\n",
        "가 생성된다.\n",
        "\n",
        "여러 개의 커널을 사용하면,\n",
        "그 개수만큼의 출력 채널(feature map)이 생성된다.\n",
        "\n",
        "예를 들어,\n",
        "- 커널 개수 = n  \n",
        "→ 출력 채널 개수 = n\n",
        "\n",
        "---\n",
        "\n",
        "## 6. 연속적인 Convolution 과정\n",
        "\n",
        "이제 생성된 출력에 대해\n",
        "- 활성화 함수(activation function)를 적용하고\n",
        "- 다시 한 번 컨볼루션 연산을 적용할 수 있다.\n",
        "\n",
        "이때 중요한 점은,\n",
        "- 입력 이미지가 n개의 채널을 가지고 있다면\n",
        "- 커널 역시 n개의 채널을 가져야 한다는 것이다.\n",
        "\n",
        "이번 레이어에서\n",
        "- 커널 개수가 m개라면\n",
        "- 출력은 m개의 채널을 가진 텐서가 된다.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. CNN 구조 정리\n",
        "\n",
        "전체 흐름을 처음부터 정리하면 다음과 같다.\n",
        "\n",
        "1. RGB 3채널 입력 이미지\n",
        "2. n개의 커널로 컨볼루션 적용  \n",
        "   → n개의 채널을 가진 feature map 생성\n",
        "3. 활성화 함수 적용\n",
        "4. m개의 커널로 다시 컨볼루션 적용  \n",
        "   → m개의 채널을 가진 feature map 생성\n",
        "5. 이 과정을 여러 번 반복\n",
        "\n",
        "이렇게 여러 개의 컨볼루션 레이어를 거치면,\n",
        "최종적으로 다수의 채널(depth)을 가진 출력 텐서가 생성된다.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Flatten과 Fully Connected Layer\n",
        "\n",
        "컨볼루션 레이어를 통해 추출된 feature들은\n",
        "`Flatten` 연산을 통해 **1차원 벡터**로 변환된다.\n",
        "\n",
        "이 벡터에\n",
        "- Fully Connected Layer를 2~3개 적용하면\n",
        "- 전체 CNN 모델을 구성할 수 있다.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. 예시 CNN Architecture\n",
        "\n",
        "하나의 예시 구조는 다음과 같다.\n",
        "\n",
        "- 입력 이미지: RGB (3채널)\n",
        "- 5×5 커널 사용\n",
        "- 채널 변화:\n",
        "  - 3 → 16\n",
        "  - 16 → 32\n",
        "  - 32 → 64\n",
        "\n",
        "이 구간은 **Feature Extraction 부분**이다.\n",
        "\n",
        "이후:\n",
        "- Flatten 적용\n",
        "- Fully Connected Layer 2개 적용\n",
        "- 마지막 출력: 10개 클래스\n",
        "- Loss Function: Cross Entropy Loss\n",
        "\n",
        "이는 전형적인 **이미지 분류 CNN 구조**이다.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. 정리\n",
        "\n",
        "- CNN에서 채널(depth)은 feature의 개수를 의미한다\n",
        "- 앞부분은 Feature Extraction\n",
        "- 뒷부분은 Classification\n",
        "- CNN 아키텍처 그림을 보면 전체 구조를 바로 해석할 수 있어야 한다\n",
        "\n",
        "---\n",
        "\n",
        "다음 시간에는  \n",
        "컨볼루션 연산에 적용할 수 있는 여러 옵션들,\n",
        "예를 들어 **stride, padding, dilation** 등에 대해 알아본다.\n"
      ],
      "metadata": {
        "id": "h1h_qasA7IyN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qvq2rQ7B7H-N",
        "outputId": "571dac22-b47e-44be-c42e-a7450a5681c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    my_device = torch.device('mps')\n",
        "elif torch.cuda.is_available():\n",
        "    my_device = torch.device('cuda')\n",
        "else:\n",
        "    my_device = torch.device('cpu')\n",
        "\n",
        "print(my_device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "JCG3IKz274hp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, 5)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 5)\n",
        "    self.conv3 = nn.Conv2d(32, 64, 5)\n",
        "\n",
        "    self.fc1 = nn.Linear(64*20*20, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.conv3(x)\n",
        "    x = torch.relu(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = torch.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net = SimpleCNN()"
      ],
      "metadata": {
        "id": "Jo7P8xM5-AkC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "PNb7zAxyAy7o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.to(my_device)\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    net.train()\n",
        "    for batch_idx, (data, label) in enumerate(trainloader):\n",
        "        data, label = data.to(my_device), label.to(my_device)\n",
        "        scores = net(data)\n",
        "        loss = criterion(scores, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    net.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, label in testloader:\n",
        "            data, label = data.to(my_device), label.to(my_device)\n",
        "            scores = net(data)\n",
        "            loss = criterion(scores, label)\n",
        "            val_loss += loss.item() * data.size(0)\n",
        "\n",
        "            predicted = scores.argmax(dim=1)\n",
        "            correct += predicted.eq(label).sum().item()\n",
        "\n",
        "    val_loss /= len(testloader.dataset)\n",
        "    val_accuracy = 100. * correct / len(testloader.dataset)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "Y-42kcaFA8QO",
        "outputId": "5879960d-eebe-4c5f-de2b-7440173fda2a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Training Loss: 0.8149, Validation Loss: 1.2992, Validation Accuracy: 52.81%\n",
            "Epoch [2/100], Training Loss: 0.6109, Validation Loss: 1.1561, Validation Accuracy: 59.40%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4056265467.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 개념            | 의미                               |\n",
        "| ------------- | -------------------------------- |\n",
        "| `loss`        | 배치 평균 loss (기본 설정)               |\n",
        "| `loss.item()` | 그 평균값을 파이썬 float로 꺼낸 것           |\n",
        "| 그래서           | `* data.size(0)`으로 다시 합으로 되돌리는 것 |\n"
      ],
      "metadata": {
        "id": "h9akggGrTkiv"
      }
    }
  ]
}