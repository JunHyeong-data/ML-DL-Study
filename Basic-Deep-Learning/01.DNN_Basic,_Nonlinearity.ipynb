{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6BSkrTIQPsTNklr5VHHZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunHyeong-data/Basic-Deep-Learning/blob/main/01.DNN_Basic%2C_Nonlinearity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 딥러닝 기초 ①: 퍼셉트론과 뉴럴 네트워크\n",
        "\n",
        "---\n",
        "\n",
        "## 1. 왜 딥러닝을 사용하는가?\n",
        "\n",
        "딥러닝과 머신러닝의 목적은 **주어진 데이터를 기반으로 새로운 데이터를 잘 예측하는 것**이다. 딥러닝에서는 이를 위해 **뉴런(Neuron)** 이라는 작은 단위를 여러 개 결합한 **뉴럴 네트워크(Neural Network)** 구조를 사용한다.\n",
        "\n",
        "딥러닝의 가장 작은 단위는 **퍼셉트론(Perceptron)** 이다.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. 선형 분류기의 직관적 이해\n",
        "\n",
        "### 2.1 1차원 분류 예제\n",
        "- 데이터가 1차원 축 위에 분포\n",
        "- 한쪽은 $\\bigcirc$ 클래스, 다른 쪽은 $\\times$ 클래스\n",
        "- 특정 기준점을 기준으로 좌/우를 나누면 분류 가능\n",
        "👉 **1차원에서는 하나의 기준점(threshold)으로 분류 가능**\n",
        "\n",
        "### 2.2 2차원 분류 예제\n",
        "- 입력 변수:  \n",
        "  - $x_1$: 가로축  \n",
        "  - $x_2$: 세로축\n",
        "- 데이터는 두 클래스로 분리 가능\n",
        "- 직선을 하나 그어 분류 가능\n",
        "\n",
        "#### 선형 분류기 예시\n",
        "$$2x_1 + x_2 - 2 = 0$$\n",
        "\n",
        "- 직선의 한쪽: 클래스 $\\bigcirc$\n",
        "- 반대쪽: 클래스 $\\times$\n",
        "👉 이를 **2차원 선형 분류기 (Linear Classifier)** 라고 한다.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. 퍼셉트론(Perceptron)\n",
        "\n",
        "### 3.1 퍼셉트론 구조\n",
        "퍼셉트론은 다음 요소로 구성된다.\n",
        "- 입력값: $x_1, x_2$\n",
        "- 가중치: $w_1, w_2$\n",
        "- 바이어스: $b$\n",
        "\n",
        "#### 퍼셉트론 수식\n",
        "$$z = w_1 x_1 + w_2 x_2 + b$$\n",
        "\n",
        "\n",
        "\n",
        "#### 예시\n",
        "$$z = 2x_1 + 1x_2 - 2$$\n",
        "\n",
        "---\n",
        "\n",
        "### 3.2 예측 예시\n",
        "- **입력: $(2, 2)$**\n",
        "  $$2 \\times 2 + 1 \\times 2 - 2 = 4$$\n",
        "  $\\rightarrow$ 양수 $\\rightarrow$ $\\bigcirc$ 클래스\n",
        "\n",
        "- **입력: $(1, 1)$**\n",
        "  $$2 \\times 1 + 1 \\times 1 - 2 = 1$$\n",
        "  $\\rightarrow$ 양수 $\\rightarrow$ $\\bigcirc$ 클래스 (문맥상 $z$값에 따라 분류)\n",
        "\n",
        "---\n",
        "\n",
        "## 4. 머신러닝이 하는 일\n",
        "머신러닝의 핵심은 다음 질문에 답하는 것이다.\n",
        "> **어떤 가중치(weight)와 바이어스(bias)를 사용해야 데이터를 가장 잘 구분할 수 있을까?**\n",
        "\n",
        "즉, 데이터를 보고 퍼셉트론의 파라미터 $w, b$를 자동으로 찾는 과정이 바로 **Machine Learning**이다.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. 선형 분류기의 한계\n",
        "\n",
        "### 5.1 선형 분리가 불가능한 데이터\n",
        "- 원 형태로 분포된 데이터나 XOR 문제 등은 직선으로는 절대 분리 불가능하다.\n",
        "👉 **아무리 많은 선형 분류기를 조합해도 결과는 여전히 선형이다.** (Linear + Linear = Linear)\n",
        "👉 즉, 선형 분류기만으로는 원, 곡선 형태의 결정 경계를 표현할 수 없다.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 6. 해결 방법: 비선형성 (Nonlinearity)\n",
        "해결책은 간단하다. 각 뉴런에 **비선형 함수(Activation Function)**를 추가하는 것이다. 이렇게 하면 뉴런이 꺼짐/켜짐과 같은 복잡하고 비선형적인 결정 경계를 학습할 수 있게 된다.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Activation Function\n",
        "Activation Function은 퍼셉트론의 출력에 적용되는 함수이다.\n",
        "$$y = f(w^T x + b)$$\n",
        "\n",
        "### 7.1 대표적인 Activation Functions\n",
        "\n",
        "#### ReLU (Rectified Linear Unit)\n",
        "$$f(x) = \\max(0, x)$$\n",
        "- 가장 널리 사용되며 계산이 간단하고 켜짐/꺼짐 구조가 명확하다.\n",
        "\n",
        "#### Sigmoid\n",
        "$$f(x) = \\frac{1}{1 + e^{-x}}$$\n",
        "- 출력 범위가 $(0, 1)$ 사이로 제한된다.\n",
        "\n",
        "#### Tanh\n",
        "$$f(x) = \\tanh(x)$$\n",
        "- 출력 범위가 $(-1, 1)$ 사이로 제한된다.\n",
        "\n",
        "\n",
        "\n",
        "### 7.2 중요한 조건\n",
        "1. **비선형성**이 존재해야 함\n",
        "2. 추후 학습(경사하강법)을 위해 **미분 가능**해야 함\n",
        "\n",
        "---\n",
        "\n",
        "## 8. 뉴럴 네트워크 (Neural Network)\n",
        "- 퍼셉트론 여러 개를 연결한 구조\n",
        "- 각 뉴런마다 Activation Function 포함\n",
        "- 비선형 분류 가능\n",
        "👉 이를 학습시키면 각 뉴런의 $weight, bias$가 자동으로 결정되어 복잡한 결정 경계를 학습한다.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. TensorFlow Playground 예시\n",
        "- 웹 기반 시각화 도구에서 확인 가능\n",
        "- Activation Function 없이 학습 $\\rightarrow$ 원형 데이터 분류 실패\n",
        "- **ReLU 사용 + 히든 레이어 추가** $\\rightarrow$ 원형 데이터 분류 성공\n",
        "👉 단순한 네트워크로도 비선형 분류가 가능해짐을 시사한다.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. 딥러닝과 딥 뉴럴 네트워크\n",
        "히든 레이어(Hidden Layer)가 깊어질수록 더 복잡한 패턴을 학습할 수 있다. 이를 **Deep Neural Network (DNN)** 라고 부른다.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 11. 실제 딥러닝 예시 (이미지 분류)\n",
        "이미지 분류의 경우 입력 차원이 매우 높다. (예: $224 \\times 224 \\times 3 \\approx 15$만 차원) 이런 고차원 데이터를 처리하고 특징을 추출하기 위해 딥러닝이 필수적으로 사용된다.\n",
        "\n",
        "---\n",
        "\n",
        "## 12. 정리\n",
        "- 딥러닝은 **뉴럴 네트워크 구조**를 사용한 머신러닝 방법\n",
        "- 퍼셉트론은 가장 작은 단위\n",
        "- 선형 분류기의 한계를 넘기 위해 **Activation Function** 사용\n",
        "- 뉴럴 네트워크 학습이란: 각 뉴런의 **weight와 bias를 찾는 과정**\n",
        "- 히든 레이어가 깊어지면 $\\rightarrow$ 딥러닝\n",
        "\n",
        "---\n",
        "\n",
        "## 다음 내용 예고\n",
        "다음 강의에서는 이 weight들을 어떻게 학습하는지 (**Backpropagation, 오차 역전파**) 를 다룬다."
      ],
      "metadata": {
        "id": "w12XjlgJP0L0"
      }
    }
  ]
}