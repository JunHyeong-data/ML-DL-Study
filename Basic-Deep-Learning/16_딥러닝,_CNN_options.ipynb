{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMomdU3c8sHjLZeHNFi04V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunHyeong-data/ML-DL-Study/blob/main/Basic-Deep-Learning/16_%EB%94%A5%EB%9F%AC%EB%8B%9D%2C_CNN_options.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Convolution 옵션 정리: Padding, Stride, Dilation\n",
        "\n",
        "이전 영상에서는 다음 내용을 학습했다.\n",
        "\n",
        "- Convolution 연산의 기본 개념\n",
        "- CNN에서 **채널(channel)** 과 **네트워크 깊이(depth)** 의 의미\n",
        "- Convolution layer 이후 **Fully Connected layer** 를 이용한 Classification\n",
        "\n",
        "사실 CNN 아키텍처의 큰 틀은 여기까지가 전부지만,  \n",
        "컴퓨터 비전 응용에서 CNN을 **제대로 이해하고 활용**하려면  \n",
        "몇 가지 중요한 옵션들을 추가로 알아야 한다.\n",
        "\n",
        "이번 문서에서는 `Conv2d`에서 사용되는 다음 세 가지 파라미터를 다룬다.\n",
        "\n",
        "- Padding\n",
        "- Stride\n",
        "- Dilation\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Convolution2D 기본 파라미터 복습\n",
        "\n",
        "PyTorch의 `Conv2d`에는 여러 인자가 존재한다.\n",
        "\n",
        "이미 알고 있는 주요 파라미터는 다음과 같다.\n",
        "\n",
        "- `in_channels` : 입력 채널 수\n",
        "- `out_channels` : 출력 채널 수\n",
        "- `kernel_size` : 커널 크기\n",
        "\n",
        "### 예시\n",
        "\n",
        "- 입력 이미지: 채널 3 (RGB)\n",
        "- 출력 채널: 16\n",
        "\n",
        "```python\n",
        "nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
        "````\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Kernel Size와 Output 크기 변화\n",
        "\n",
        "입력 이미지의 크기가 다음과 같다고 가정하자.\n",
        "\n",
        "* 입력 크기: `(3, 224, 224)`\n",
        "\n",
        "### (1) Kernel Size = 3\n",
        "\n",
        "* Output 크기: `(16, 222, 222)`\n",
        "\n",
        "### (2) Kernel Size = 5\n",
        "\n",
        "* Output 크기: `(16, 220, 220)`\n",
        "\n",
        "➡️ 이유\n",
        "Convolution은 **슬라이딩 윈도우 방식**이기 때문에\n",
        "커널 크기가 커질수록 출력 이미지 크기는 줄어든다.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Padding\n",
        "\n",
        "### Padding이 필요한 이유\n",
        "\n",
        "Convolution 연산을 수행하면 출력 이미지 크기가 계속 줄어든다.\n",
        "이를 방지하기 위해 **입력 이미지 가장자리에 값을 추가**하는 것이 Padding이다.\n",
        "\n",
        "일반적으로 가장 많이 사용하는 방식은 **Zero Padding**이다.\n",
        "\n",
        "### Padding의 효과\n",
        "\n",
        "* 입력 크기를 임시로 확장\n",
        "* Convolution 이후에도 **출력 크기 유지 가능**\n",
        "\n",
        "### 예시 (PyTorch)\n",
        "\n",
        "```python\n",
        "# 입력 텐서\n",
        "input = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# Padding 없이 Conv\n",
        "conv = nn.Conv2d(3, 16, kernel_size=5)\n",
        "output = conv(input)\n",
        "# 출력 크기: (1, 16, 220, 220)\n",
        "\n",
        "# Padding 적용\n",
        "conv_pad = nn.Conv2d(3, 16, kernel_size=5, padding=2)\n",
        "output_pad = conv_pad(input)\n",
        "# 출력 크기: (1, 16, 224, 224)\n",
        "```\n",
        "\n",
        "➡️ Kernel size가 5일 때, padding을 2로 주면 입력과 출력 크기가 동일해진다.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Stride\n",
        "\n",
        "### Stride란?\n",
        "\n",
        "Stride는 **슬라이딩 윈도우가 이동하는 간격**이다.\n",
        "\n",
        "* 기본값: `stride = 1`\n",
        "* 값이 커질수록 출력 크기는 작아진다.\n",
        "\n",
        "### Stride를 사용하는 이유\n",
        "\n",
        "CNN은 일반적으로 **아주 깊은 구조**를 가진다.\n",
        "공간 크기를 줄이지 않으면 연산량이 지나치게 커진다.\n",
        "\n",
        "➡️ Stride는 **효과적인 다운샘플링 방법**이다.\n",
        "\n",
        "---\n",
        "\n",
        "### 예시 1: 작은 입력\n",
        "\n",
        "* 입력 크기: `(1, 4, 4)`\n",
        "* Kernel size: 2\n",
        "\n",
        "#### Stride = 1\n",
        "\n",
        "* 출력 크기: `(1, 3, 3)`\n",
        "\n",
        "#### Stride = 2\n",
        "\n",
        "* 슬라이딩 윈도우가 한 칸씩이 아니라 두 칸씩 이동\n",
        "* 출력 크기 감소\n",
        "\n",
        "---\n",
        "\n",
        "### 예시 2: 실제 이미지 크기\n",
        "\n",
        "* 입력 크기: `(224, 224)`\n",
        "* Kernel size: 3\n",
        "* Stride: 2\n",
        "\n",
        "➡️ 출력 크기: `(112, 112)`\n",
        "\n",
        "```python\n",
        "conv = nn.Conv2d(3, 16, kernel_size=3, stride=2)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Dilation\n",
        "\n",
        "### Dilation이란?\n",
        "\n",
        "Dilation은 Convolution 커널을 **띄엄띄엄 떨어뜨려 적용**하는 방식이다.\n",
        "\n",
        "* 커널의 실제 크기는 유지\n",
        "* **수용 영역(Receptive Field)** 은 커짐\n",
        "\n",
        "즉, 한 번의 Convolution으로 **더 넓은 영역의 정보를 학습**할 수 있다.\n",
        "\n",
        "---\n",
        "\n",
        "### Dilation의 특징\n",
        "\n",
        "* 슬라이딩 윈도우 방식은 동일\n",
        "* 커널이 입력 이미지와 매칭되는 방식만 달라짐\n",
        "* 작은 커널로 넓은 패턴 학습 가능\n",
        "\n",
        "### 활용 예시\n",
        "\n",
        "* 이미지 세그멘테이션 네트워크\n",
        "* 넓은 문맥 정보(Context)가 중요한 경우\n",
        "\n",
        "---\n",
        "\n",
        "## 6. 정리\n",
        "\n",
        "이번 문서에서 다룬 Convolution 옵션은 다음과 같다.\n",
        "\n",
        "| 옵션       | 역할               |\n",
        "| -------- | ---------------- |\n",
        "| Padding  | 출력 크기 유지         |\n",
        "| Stride   | 출력 크기 감소 (다운샘플링) |\n",
        "| Dilation | 넓은 영역의 패턴 학습     |\n",
        "\n",
        "이 옵션들은 CNN 아키텍처를 설명할 때 **항상 등장**하며,\n",
        "네트워크 구조를 이해하는 데 매우 중요하다.\n",
        "\n",
        "---\n",
        "\n",
        "다음 단계에서는 **Pooling Layer** 에 대해 알아본다."
      ],
      "metadata": {
        "id": "xWxze0b1URoG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kitwrgekUFsJ",
        "outputId": "455b59eb-ab97-4945-9c1a-4ca01562e60f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 220, 220])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input_tensor = torch.randn(1, 3, 224, 224)\n",
        "kernel_size = 5\n",
        "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=kernel_size)\n",
        "output_tensor = conv_layer(input_tensor)\n",
        "\n",
        "print(output_tensor.shape)\n",
        "#torch.randn은 평균 0인 정규분포에서 뽑은 랜덤 값으로 Tensor를 만들어서\n",
        "#실제 이미지 입력을 흉내 내는 용도로 쓰인다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 차원  | 의미             |\n",
        "| --- | -------------- |\n",
        "| 1   | 배치 크기 (이미지 1장) |\n",
        "| 3   | 채널 수 (RGB)     |\n",
        "| 224 | 높이             |\n",
        "| 224 | 너비             |\n"
      ],
      "metadata": {
        "id": "6U0GFm7aXte1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.randn(1, 3, 224, 224)\n",
        "kernel_size = 5\n",
        "padding = 2\n",
        "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=kernel_size, padding=padding)\n",
        "output_tensor = conv_layer(input_tensor)\n",
        "print(output_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrM-9p5WXuFc",
        "outputId": "215e105f-5537-42a1-b27e-b61309178d56"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.randn(1, 3, 224, 224)\n",
        "kernel_size = 2\n",
        "stride = 2\n",
        "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=kernel_size, stride=stride)\n",
        "output_tensor = conv_layer(input_tensor)\n",
        "print(output_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwkLf3CIYZor",
        "outputId": "2108bb76-5d52-4f4a-a2f8-9e221f76872d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 112, 112])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.randn(1, 3, 224, 224)\n",
        "kernel_size = 2\n",
        "dilation = 2\n",
        "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=kernel_size, dilation=dilation)\n",
        "output_tensor = conv_layer(input_tensor)\n",
        "print(output_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le_BBB9qY8Un",
        "outputId": "3e8eda16-18b3-4cb0-b12f-8e71581c7d7d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 222, 222])\n"
          ]
        }
      ]
    }
  ]
}