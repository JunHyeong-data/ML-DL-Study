{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQgSH8NAC1CkyYXrqn7BXO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunHyeong-data/ML-DL-Study/blob/main/Basic-Deep-Learning/22_%EB%94%A5%EB%9F%AC%EB%8B%9D%2C_%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5%2C_fine_tuning%2C_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning (íŠ¸ëœìŠ¤í¼ ëŸ¬ë‹) ì •ë¦¬\n",
        "\n",
        "## 1. íŠ¸ëœìŠ¤í¼ ëŸ¬ë‹ì´ë€?\n",
        "\n",
        "**íŠ¸ëœìŠ¤í¼ ëŸ¬ë‹(Transfer Learning)** ì´ë€  \n",
        "ì´ë¯¸ **ë¯¸ë¦¬ í•™ìŠµ(pretrained)** ë˜ì–´ ìˆëŠ” ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ë¥¼ ê°€ì ¸ì™€  \n",
        "ë‚´ê°€ ì›í•˜ëŠ” ë°ì´í„°ë¡œ **ì¬í•™ìŠµ(fine-tuning)** ì‹œí‚¤ëŠ” ë°©ë²•ì´ë‹¤.\n",
        "\n",
        "ì‹¤ë¬´ ë° í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ëŒ€ë¶€ë¶„ì˜ ê²½ìš°  \n",
        "ëª¨ë¸ì„ **ì²˜ìŒë¶€í„° í•™ìŠµì‹œí‚¤ì§€ ì•Šê³ ** íŠ¸ëœìŠ¤í¼ ëŸ¬ë‹ì„ ì‚¬ìš©í•œë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. ì™œ íŠ¸ëœìŠ¤í¼ ëŸ¬ë‹ì´ í•„ìš”í•œê°€?\n",
        "\n",
        "### 2.1 ë°ì´í„° ë¬¸ì œ\n",
        "\n",
        "- ëŒ€ê·œëª¨ ëª¨ë¸ì„ ì²˜ìŒë¶€í„° í•™ìŠµí•˜ë ¤ë©´ **ë§‰ëŒ€í•œ ë°ì´í„°**ê°€ í•„ìš”\n",
        "- ì˜ˆ:\n",
        "  - ImageNet-1K\n",
        "  - ì•½ **130ë§Œ ì¥**ì˜ ì´ë¯¸ì§€\n",
        "- ëŒ€ë¶€ë¶„ì˜ ê°œì¸ì´ë‚˜ ê¸°ì—…ì€ ì´ ì •ë„ ë°ì´í„°ë¥¼ í™•ë³´í•˜ê¸° ì–´ë µë‹¤.\n",
        "\n",
        "### 2.2 ì—°ì‚° ë¹„ìš© ë¬¸ì œ\n",
        "\n",
        "- ëŒ€í˜• CNN ëª¨ë¸ í•™ìŠµì€ **ì‹œê°„ê³¼ ë¹„ìš©ì´ ë§¤ìš° í¼**\n",
        "- ì˜ˆ:\n",
        "  - ResNet-152\n",
        "  - ê³¼ê±° ì„¸ëŒ€ GPU ê¸°ì¤€ ì•½ **3ì£¼** ì´ìƒ í•™ìŠµ í•„ìš”\n",
        "\n",
        "â¡ï¸ **í˜„ì‹¤ì ìœ¼ë¡œ ëŒ€ë¶€ë¶„ì€ ì²˜ìŒë¶€í„° í•™ìŠµì´ ë¶ˆê°€ëŠ¥**\n",
        "\n",
        "---\n",
        "\n",
        "## 3. íŠ¸ëœìŠ¤í¼ ëŸ¬ë‹ì´ ì˜ ë™ì‘í•˜ëŠ” ì´ìœ \n",
        "\n",
        "CNNì€ í•™ìŠµ ê³¼ì •ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ì˜ íŠ¹ì§•ì„ í•™ìŠµí•œë‹¤.\n",
        "\n",
        "- **Low-level feature**\n",
        "  - ì—£ì§€(edge)\n",
        "  - ì½”ë„ˆ(corner)\n",
        "  - í…ìŠ¤ì²˜(texture)\n",
        "- **High-level feature**\n",
        "  - ë¬¼ì²´ì˜ í˜•íƒœ\n",
        "  - ì˜ë¯¸ ìˆëŠ” íŒ¨í„´\n",
        "\n",
        "ImageNetìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì€  \n",
        "ì´ë¯¸ **ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ íŠ¹ì§•ì„ ë§¤ìš° ì˜ í•™ìŠµ**í•˜ê³  ìˆë‹¤.\n",
        "\n",
        "â¡ï¸ ë§Œì•½ ìš°ë¦¬ê°€ í’€ê³ ì í•˜ëŠ” ë¬¸ì œê°€  \n",
        "ImageNetê³¼ **ë„ë©”ì¸ì´ ë¹„ìŠ·í•˜ë‹¤ë©´**,  \n",
        "ì´ íŠ¹ì§•ì„ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. íŠ¸ëœìŠ¤í¼ ëŸ¬ë‹ ì˜ˆì‹œ\n",
        "\n",
        "- í¬ì¼“ëª¬ ì´ë¯¸ì§€ ë¶„ë¥˜\n",
        "- ì„¸í¬ ì´ë¯¸ì§€ ë¶„ë¥˜ (ì˜ë£Œ ì´ë¯¸ì§€)\n",
        "- ê°•ì•„ì§€ / ê³ ì–‘ì´ ë¶„ë¥˜\n",
        "\n",
        "ì´ëŸ° ë¬¸ì œë“¤ì€:\n",
        "- ì²˜ìŒë¶€í„° í•™ìŠµí•˜ê¸°ì—” ë°ì´í„°ê°€ ë¶€ì¡±\n",
        "- í•˜ì§€ë§Œ **í”„ë¦¬íŠ¸ë ˆì¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©´ ì ì€ ë°ì´í„°ë¡œë„ ê³ ì„±ëŠ¥ ê°€ëŠ¥**\n",
        "\n",
        "---\n",
        "\n",
        "## 5. íŠ¸ëœìŠ¤í¼ ëŸ¬ë‹ ì ìš© ì „ëµ\n",
        "\n",
        "ë°ì´í„° ì–‘ê³¼ ë„ë©”ì¸ ìœ ì‚¬ì„±ì— ë”°ë¼ ì „ëµì´ ë‹¬ë¼ì§„ë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "### 5.1 ImageNetê³¼ ë§¤ìš° ë¹„ìŠ·í•œ ê²½ìš°\n",
        "\n",
        "ì˜ˆ: ê°•ì•„ì§€ / ê³ ì–‘ì´ ë¶„ë¥˜\n",
        "\n",
        "- ë§ˆì§€ë§‰ **Fully Connected Layerë§Œ í•™ìŠµ**\n",
        "- ë‚˜ë¨¸ì§€ ë ˆì´ì–´ëŠ” **freeze (ê³ ì •)**\n",
        "\n",
        "```text\n",
        "[ Backbone (Frozen) ] â†’ [ FC Layer (Train) ]\n",
        "````\n",
        "\n",
        "---\n",
        "\n",
        "### 5.2 ë„ë©”ì¸ì´ ë‹¤ë¥¸ ê²½ìš°\n",
        "\n",
        "ì˜ˆ:\n",
        "\n",
        "* ì˜ë£Œ ì˜ìƒ (X-ray, MRI)\n",
        "* ì• ë‹ˆë©”ì´ì…˜ ì´ë¯¸ì§€ (í¬ì¼“ëª¬)\n",
        "\n",
        "ì´ ê²½ìš°:\n",
        "\n",
        "* ImageNetê³¼ í”¼ì²˜ ë¶„í¬ê°€ ë‹¤ë¦„\n",
        "* ë” ë§ì€ ë ˆì´ì–´ë¥¼ í•™ìŠµí•´ì•¼ í•¨\n",
        "* ë°ì´í„°ë„ ë” ë§ì´ í•„ìš”\n",
        "\n",
        "â¡ï¸ ì´ ê³¼ì •ì„ **Fine-Tuning** ì´ë¼ê³  í•¨\n",
        "\n",
        "---\n",
        "\n",
        "### 5.3 ì‹¤ë¬´ ê²½í—˜ ê¸°ë°˜ ê°€ì´ë“œ\n",
        "\n",
        "* í´ë˜ìŠ¤ë‹¹ ìµœì†Œ **1,000 ~ 2,000ì¥** ë°ì´í„° ê¶Œì¥\n",
        "* ê°€ëŠ¥í•œ ê²½ìš°:\n",
        "\n",
        "  * **ëª¨ë“  ë ˆì´ì–´ë¥¼ fine-tuning** í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì•ˆì •ì \n",
        "  * ì—¬ëŸ¬ íŠ¸ë¦­ë³´ë‹¤ ë°ì´í„° í™•ë³´ê°€ ë” ì¤‘ìš”\n",
        "\n",
        "---\n",
        "\n",
        "## 6. ë‹¤ì–‘í•œ íŠ¸ëœìŠ¤í¼ ëŸ¬ë‹ ë°©ë²•ë“¤\n",
        "\n",
        "ì´ë¡ ì ìœ¼ë¡œëŠ” ë§¤ìš° ë§ì€ ì˜µì…˜ì´ ì¡´ì¬í•œë‹¤.\n",
        "\n",
        "* í•˜ìœ„ ë ˆì´ì–´ë§Œ freeze\n",
        "* ìƒìœ„ ë ˆì´ì–´ë§Œ freeze\n",
        "* ë ˆì´ì–´ë³„ ë‹¤ë¥¸ learning rate\n",
        "* BatchNorm ë ˆì´ì–´ë§Œ ê³ ì •\n",
        "* ë¶€ë¶„ fine-tuning\n",
        "\n",
        "â¡ï¸ í•˜ì§€ë§Œ ë³µì¡ë„ê°€ ë†’ê³  ì‹¤ë¬´ì—ì„œëŠ” ê´€ë¦¬ê°€ ì–´ë ¤ì›€\n",
        "\n",
        "---\n",
        "\n",
        "## 7. ì‹¤ìŠµ ì˜ˆì œ ê°œìš”\n",
        "\n",
        "### 7.1 ì‚¬ìš© ëª¨ë¸\n",
        "\n",
        "* ResNet-18\n",
        "* ImageNet-1Kë¡œ pretrained ëœ ëª¨ë¸\n",
        "\n",
        "---\n",
        "\n",
        "### 7.2 ë°ì´í„°ì…‹\n",
        "\n",
        "* CIFAR-10\n",
        "* ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: 32 Ã— 32\n",
        "* ResNet ì…ë ¥ ìš”êµ¬ í¬ê¸°: 224 Ã— 224\n",
        "\n",
        "â¡ï¸ `Resize(224, 224)` ì ìš©\n",
        "\n",
        "---\n",
        "\n",
        "### 7.3 ë°ì´í„° ì „ì²˜ë¦¬\n",
        "\n",
        "* Resize\n",
        "* ToTensor\n",
        "* Normalize\n",
        "\n",
        "```text\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std  = [0.229, 0.224, 0.225]\n",
        "```\n",
        "\n",
        "> ì´ ê°’ì€ ImageNet pretrained ëª¨ë¸ì—ì„œ ì‚¬ìš©ëœ ê°’\n",
        "> ë°ì´í„°ê°€ ì¶©ë¶„íˆ ë§ë‹¤ë©´ ê¼­ ë™ì¼í•  í•„ìš”ëŠ” ì—†ìŒ\n",
        "\n",
        "---\n",
        "\n",
        "## 8. ëª¨ë¸ ìˆ˜ì •\n",
        "\n",
        "### 8.1 ë§ˆì§€ë§‰ ë ˆì´ì–´ ë³€ê²½\n",
        "\n",
        "ImageNet:\n",
        "\n",
        "* ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜: 1000\n",
        "\n",
        "CIFAR-10:\n",
        "\n",
        "* ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜: 10\n",
        "\n",
        "```python\n",
        "model.fc = nn.Linear(512, 10)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 8.2 íŒŒë¼ë¯¸í„° ê³ ì • ì—¬ë¶€\n",
        "\n",
        "* ì „ì²´ freeze ê°€ëŠ¥\n",
        "* ì¼ë¶€ freeze ê°€ëŠ¥\n",
        "* ì „ì²´ fine-tuning ê°€ëŠ¥\n",
        "\n",
        "ì´ë²ˆ ì˜ˆì œì—ì„œëŠ”:\n",
        "\n",
        "* **ëª¨ë“  ë ˆì´ì–´ fine-tuning**\n",
        "\n",
        "---\n",
        "\n",
        "## 9. í•™ìŠµ ì„¤ì •\n",
        "\n",
        "* Loss Function: CrossEntropyLoss\n",
        "* Optimizer: Adam\n",
        "* í•™ìŠµ / ê²€ì¦ ë£¨í”„ëŠ” ê¸°ì¡´ê³¼ ë™ì¼\n",
        "\n",
        "---\n",
        "\n",
        "## 10. ê²°ê³¼\n",
        "\n",
        "* ê¸°ì¡´ CNN:\n",
        "\n",
        "  * Validation Accuracy â‰ˆ 70%\n",
        "* Transfer Learning ì ìš©:\n",
        "\n",
        "  * Validation Accuracy â‰ˆ **95%**\n",
        "* í•™ìŠµ ì‹œê°„:\n",
        "\n",
        "  * ì•½ **10 ~ 30ë¶„**\n",
        "\n",
        "â¡ï¸ **ì ì€ ë¹„ìš©ìœ¼ë¡œ ë§¤ìš° í° ì„±ëŠ¥ í–¥ìƒ**\n",
        "\n",
        "---\n",
        "\n",
        "## 11. ì •ë¦¬\n",
        "\n",
        "* ì»´í“¨í„° ë¹„ì „ì—ì„œ **Transfer Learningì€ í‘œì¤€**\n",
        "* ëŒ€ë¶€ë¶„ì˜ CNN ëª¨ë¸ì€:\n",
        "\n",
        "  * Pretrained Backbone + Task-specific Head êµ¬ì¡°\n",
        "* ì‹¤ë¬´ì—ì„œëŠ”:\n",
        "\n",
        "  * ëª¨ë¸ êµ¬ì¡°ë³´ë‹¤ **ë°ì´í„° í™•ë³´ê°€ ê°€ì¥ ì¤‘ìš”**\n",
        "\n",
        "---\n",
        "\n",
        "## 12. ë‹¤ìŒ ì±•í„°\n",
        "\n",
        "* Object Detection\n",
        "* Segmentation\n",
        "\n",
        "CNN ê¸°ì´ˆ ì±•í„° ì¢…ë£Œ ğŸ‰\n",
        "```\n"
      ],
      "metadata": {
        "id": "iQpOJ7_tYooL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Too4Zoo8YoFk",
        "outputId": "13d5bdfc-7683-4e4d-938f-62ac45368e6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    my_device = torch.device('mps')\n",
        "elif torch.cuda.is_available():\n",
        "    my_device = torch.device('cuda')\n",
        "else:\n",
        "    my_device = torch.device('cpu')\n",
        "\n",
        "print(my_device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406] , std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=8)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBRs9jySZzX2",
        "outputId": "6540a6d9-b412-4436-892a-2384dae540b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:13<00:00, 13.1MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "weights = models.ResNet18_Weights.DEFAULT\n",
        "model = models.resnet18(weights=weights)\n",
        "model.fc = nn.Linear(512, 10)  # CIFAR10 has 10 classes\n",
        "# print(net)\n",
        "\n",
        "# Freeze all layers\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# # Unfreeze the last fully connected layer (fc)\n",
        "# for param in model.fc.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4LOHGdeZ3ej",
        "outputId": "6ea37e86-a547-47ee-fd23-408ff2778fbc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 234MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "model.to(my_device)\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()  # Start the timer\n",
        "    model.train()\n",
        "    for batch_idx, (data, label) in enumerate(trainloader):\n",
        "        data, label = data.to(my_device), label.to(my_device)\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, label in testloader:\n",
        "            data, label = data.to(my_device), label.to(my_device)\n",
        "            scores = model(data)\n",
        "            loss = criterion(scores, label)\n",
        "            val_loss += loss.item() * data.size(0)\n",
        "\n",
        "            predicted = scores.argmax(dim=1)\n",
        "            correct += predicted.eq(label).sum().item()\n",
        "\n",
        "    val_loss /= len(testloader.dataset)\n",
        "    val_accuracy = 100. * correct / len(testloader.dataset)\n",
        "    end_time = time.time()  # End the timer\n",
        "    elapsed_time = end_time - start_time  # Compute the elapsed time\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%, Time: {elapsed_time:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wolNAIavZ6zs",
        "outputId": "e52fcdab-e575-4d78-b605-54de8a5ce3c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Training Loss: 0.2684, Validation Loss: 0.3739, Validation Accuracy: 88.84%, Time: 177.94s\n",
            "Epoch [2/100], Training Loss: 0.1478, Validation Loss: 0.2575, Validation Accuracy: 91.90%, Time: 177.21s\n",
            "Epoch [3/100], Training Loss: 0.1255, Validation Loss: 0.2167, Validation Accuracy: 93.00%, Time: 176.90s\n",
            "Epoch [4/100], Training Loss: 0.1559, Validation Loss: 0.1995, Validation Accuracy: 93.29%, Time: 177.67s\n",
            "Epoch [5/100], Training Loss: 0.0861, Validation Loss: 0.1898, Validation Accuracy: 93.66%, Time: 177.18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImageNetìœ¼ë¡œ pretrained ëœ ResNetì€\n",
        "â€œ224 Ã— 224 ì´ë¯¸ì§€ + ImageNet ë¶„í¬â€ë¥¼ ê°€ì •í•˜ê³  í•™ìŠµë˜ì—ˆê¸° ë•Œë¬¸ì—\n",
        "CIFAR-10ì„ ì“¸ ë•Œë„ Resize((224,224))ë¡œ\n",
        "ê·¸ ê°€ì •ì„ ë§ì¶°ì£¼ëŠ” ê²ƒì´ë‹¤."
      ],
      "metadata": {
        "id": "iVtw-Nx9dl1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì…ë ¥ ì´ë¯¸ì§€\n",
        " â†’ Conv + BN + ReLU\n",
        " â†’ Residual Block Ã— ì—¬ëŸ¬ ê°œ\n",
        " â†’ Global Average Pooling\n",
        " â†’ Fully Connected Layer (fc)\n",
        " â†’ ì¶œë ¥\n"
      ],
      "metadata": {
        "id": "8THQr4wKeglA"
      }
    }
  ]
}