# Hidden Markov Model β€“ Decoding & Learning (2κ°• μ •λ¦¬)

## 1. κ°•μ κ°μ”
λ³Έ κ°•μλ” Hidden Markov Model(HMM) λ‘ λ²μ§Έ κ°•μμ΄λ‹¤. 1κ°•μ—μ„ λ‹¤λ£¬ HMMμ κ°λ…κ³Ό Evaluation λ¬Έμ λ¥Ό λ³µμµν•κ³ , μƒλ΅μ΄ μ£Όμ μΈ **Decoding λ¬Έμ **μ™€ **Learning λ¬Έμ **μ κ°μ”λ¥Ό λ‹¤λ£¬λ‹¤.

---

## 2. HMM νλΌλ―Έν„° λ³µμµ
HMMμ€ μ΄ 3κ°μ ν™•λ¥  νλΌλ―Έν„°(Probability Matrix)λ΅ κµ¬μ„±λλ‹¤.
<img width="1457" height="911" alt="image" src="https://github.com/user-attachments/assets/fec7d1a5-2502-4522-803f-98d8b54fce43" />

### (1) Initial State Probability β€“ $\pi$
$$\pi_i = P(q_1 = i)$$
- μ²« μ‹μ μ—μ„ hidden stateκ°€ μ‹μ‘λ  ν™•λ¥ μ΄λ‹¤.

### (2) State Transition Probability β€“ $A$
$$a_{ij} = P(q_{t+1}=j \mid q_t=i)$$
- ν• hidden stateμ—μ„ λ‹¤λ¥Έ hidden stateλ΅ μ΄λ™ν•  ν™•λ¥ ($\text{Hidden} \to \text{Hidden}$)μ΄λ‹¤.

| From \ To | $S_1$ | $S_2$ |
| :--- | :--- | :--- |
| **$S_1$** | $a_{11}$ | $a_{12}$ |
| **$S_2$** | $a_{21}$ | $a_{22}$ |

### (3) Emission Probability β€“ $B$
$$b_j(k) = P(O_t = k \mid q_t = j)$$
- νΉμ • hidden stateμ—μ„ μ–΄λ–¤ κ΄€μΈ΅κ°’μ΄ λ°μƒν•  ν™•λ¥ ($\text{Hidden} \to \text{Observation}$)μ΄λ‹¤.

| State | Walk | Study | Shop |
| :--- | :--- | :--- | :--- |
| **Rain** | 0.1 | 0.4 | 0.5 |
| **Sunny** | 0.6 | 0.3 | 0.1 |

---

## 3. HMMμ μ„Έ κ°€μ§€ λ¬Έμ 
<img width="1467" height="883" alt="image" src="https://github.com/user-attachments/assets/33d34ecb-acbd-4849-ad81-a575713e0477" />

### β… Problem 1. Evaluation
- **μ •μ:** κ΄€μΈ΅ μ‹ν€€μ¤κ°€ μ£Όμ–΄μ΅μ„ λ• λ¨λΈμ—μ„ λ°μƒν•  ν™•λ¥  $P(O \mid \lambda)$μ€?
- **ν•΄κ²°:** Forward / Backward Algorithm (**$\sum$ μ—°μ‚°**)

### β… Problem 2. Decoding (μ΄λ² κ°•μ ν•µμ‹¬)
- **μ •μ:** κ΄€μΈ΅ μ‹ν€€μ¤κ°€ μ£Όμ–΄μ΅μ„ λ• κ°€μ¥ κ°€λ¥μ„± λ†’μ€ hidden state sequenceλ”?
$$\arg\max_Q P(Q \mid O, \lambda)$$
- **ν•΄κ²°:** **Viterbi Algorithm** (**$\max$ μ—°μ‚°**)

### β… Problem 3. Learning
- **μ •μ:** κ΄€μΈ΅ λ°μ΄ν„°λ§ μ£Όμ–΄μ΅μ„ λ• HMM νλΌλ―Έν„°($\pi, A, B$)λ¥Ό μ¶”μ •ν•λΌ.
- **ν•΄κ²°:** Baumβ€“Welch Algorithm (EM Algorithm)

---

## 4. Decoding Problem μ •μ
<img width="1506" height="1061" alt="image" src="https://github.com/user-attachments/assets/cf00156f-1f15-4167-a38b-8c13f957ce40" />

κ΄€μΈ΅ μ‹ν€€μ¤ $O = [\text{μ‚°μ±…, μ‚°μ±…, μ—°κµ¬, μ‡Όν•‘}]$κ°€ μ£Όμ–΄μ΅μ„ λ•, κ° μ‹μ μ μ€λ‹‰ μƒνƒ $S = \{\text{λΉ„, ν•΄}\}$ μ¤‘ μ „μ²΄ μ‹ν€€μ¤ ν™•λ¥ μ„ μµλ€ν™”ν•λ” **μµμ μ μƒνƒ κ²½λ΅**λ¥Ό μ°Ύλ” κ²ƒμ΄ λ©ν‘μ΄λ‹¤.



---

## 5. Viterbi Algorithm
<img width="1291" height="648" alt="image" src="https://github.com/user-attachments/assets/3cb03bc2-a5b9-423a-b955-12fa0bbeb479" />
<img width="1281" height="600" alt="image" src="https://github.com/user-attachments/assets/0c245ced-61bf-4021-a365-9471dc5b69df" />
<img width="1413" height="671" alt="image" src="https://github.com/user-attachments/assets/af34ae80-2a33-488b-8c16-9b12b18c80b6" />
<img width="1405" height="679" alt="image" src="https://github.com/user-attachments/assets/647f1665-d40c-4ab6-b426-158c43a36415" />
<img width="1501" height="986" alt="image" src="https://github.com/user-attachments/assets/6cb8508b-50b4-48bf-8f09-eff6a86849f2" />

Viterbiλ” Dynamic Programmingμ„ μ‚¬μ©ν•μ—¬ Decoding λ¬Έμ λ¥Ό ν¨μ¨μ μΌλ΅ ν•΄κ²°ν•λ‹¤.

### 5.1 Viterbi Probability μ •μ
$\delta_t(j)$λ” μ‹κ°„ $t$μ—μ„ μƒνƒ $j$μ— λ„λ‹¬ν•  μ μλ” **μµλ€ ν™•λ¥  κ²½λ΅μ ν™•λ¥ **μ„ μλ―Έν•λ‹¤.

### 5.2 Initialization
$$\delta_1(j) = \pi_j b_j(O_1)$$

### 5.3 Recursion
$$\delta_t(j) = \max_i \left[ \delta_{t-1}(i)a_{ij} \right] b_j(O_t)$$
π‘‰ **Forward μ•κ³ λ¦¬μ¦κ³Όμ κ²°μ •μ  μ°¨μ΄:** μ΄μ „ μ‹μ μ ν™•λ¥ λ“¤μ„ λ”ν•λ”($\sum$) λ€μ‹ , κ°€μ¥ ν° κ°’ ν•λ‚λ¥Ό μ„ νƒ($\max$)ν•λ‹¤.

### 5.4 Termination
$$P^* = \max_i \delta_T(i)$$

### 5.5 Backtracking
λ§μ§€λ§‰ μ‹μ μ—μ„ κ°€μ¥ ν° ν™•λ¥ μ„ κ°€μ§„ μƒνƒλ¥Ό μ„ νƒν• ν›„, κΈ°λ΅ν•΄λ‘” κ²½λ΅λ¥Ό λ”°λΌ **μ—­μ¶”μ (Backtracking)**ν•μ—¬ μµμ μ hidden state sequenceλ¥Ό λ³µμ›ν•λ‹¤.

<img width="1429" height="917" alt="image" src="https://github.com/user-attachments/assets/e2f969d7-9463-45f6-9607-de775757610a" />


---

## 6. Forward vs Viterbi λΉ„κµ
<img width="1470" height="1076" alt="image" src="https://github.com/user-attachments/assets/cf7d22f5-5e11-4579-9be9-08f7a29ab4ac" />

| κµ¬λ¶„ | Forward | Viterbi |
| :--- | :--- | :--- |
| **λ©μ ** | ν™•λ¥  κ³„μ‚° | μƒνƒ(κ²½λ΅) μ¶”μ • |
| **μ—°μ‚°** | ν•©(sum) | μµλ€(max) |
| **κ²°κ³Ό** | μ‹ν€€μ¤ μ „μ²΄ ν™•λ¥  | μµμ  μƒνƒ κ²½λ΅ |
| **λ¬Έμ ** | Evaluation | Decoding |

---

## 7. Dynamic Programming ν•µμ‹¬ μ•„μ΄λ””μ–΄
Viterbiλ” ν„μ¬ μ‹μ μ μµμ  κ²°μ •μ΄ μ΄μ „ μ‹μ μ μ •λ³΄μ—λ§ μμ΅΄ν•λ‹¤λ” λ§μ½”ν”„ μ„±μ§μ„ μ΄μ©ν•λ‹¤.
- κ³„μ‚° λ³µμ΅λ„: $O(N^2 T)$ ($N$: μƒνƒ μ, $T$: μ‹ν€€μ¤ κΈΈμ΄)
- μ „μ μ΅°μ‚¬($N^T$)μ— λΉ„ν•΄ μ••λ„μ μΌλ΅ ν¨μ¨μ μ΄λ‹¤.

---

## 8. Learning Problem (λ‹¤μ κ°•μ μκ³ )
<img width="1418" height="877" alt="image" src="https://github.com/user-attachments/assets/70c0b8c6-9373-4110-b164-2a2b5d1dae46" />

ν„μ‹¤μ—μ„λ” μ€λ‹‰ μƒνƒ μ‹ν€€μ¤ μ—†μ΄ κ΄€μΈ΅ λ°μ΄ν„°λ§ μ΅΄μ¬ν•λ” κ²½μ°κ°€ λ€λ¶€λ¶„μ΄λ‹¤.

- **λ©ν‘:** $\arg\max_\lambda P(O \mid \lambda)$λ¥Ό λ§μ΅±ν•λ” νλΌλ―Έν„° $\lambda = (\pi, A, B)$ μ¶”μ •
- **ν•΄κ²°:** **Baumβ€“Welch Algorithm**
  - EM Algorithm κΈ°λ° μµμ ν™”
  - Forward ν™•λ¥ ($\alpha$)κ³Ό Backward ν™•λ¥ ($\beta$)μ„ λ¨λ‘ μ‚¬μ©ν•μ—¬ νλΌλ―Έν„°λ¥Ό μ—…λ°μ΄νΈν•¨.

---

## 9. μ „μ²΄ κµ¬μ΅° μ”μ•½
**HMM ν•µμ‹¬ μ•κ³ λ¦¬μ¦**
1. **Evaluation** $\rightarrow$ Forward / Backward
2. **Decoding** $\rightarrow$ Viterbi
3. **Learning** $\rightarrow$ Baum-Welch (EM)

---

## β… ν•µμ‹¬ μ”μ•½
- HMMμ€ 3κ°μ νλΌλ―Έν„°($\pi, A, B$)λ΅ κµ¬μ„±λλ‹¤.
- **Evaluation**μ€ μ „μ²΄ ν™•λ¥ μ„ κµ¬ν•κΈ° μ„ν•΄ $\sum$ μ—°μ‚°μ„ μν–‰ν•λ‹¤.
- **Decoding**μ€ μµμ  κ²½λ΅λ¥Ό μ°ΎκΈ° μ„ν•΄ $\max$ μ—°μ‚°μ„ μν–‰ν•λ©°, Viterbi μ•κ³ λ¦¬μ¦μ΄ μ“°μΈλ‹¤.
- **Learning** λ¬Έμ μ—μ„λ” Forwardμ™€ Backward ν™•λ¥ μ„ λ¨λ‘ κ²°ν•©ν•μ—¬ λ¨λΈμ„ ν•™μµμ‹ν‚¨λ‹¤.

# Hidden Markov Model β€“ Baumβ€“Welch (EM Algorithm) μ •λ¦¬

## 1. μ΄λ² κ°•μμ ν•µμ‹¬ μ£Όμ 
μ΄λ² κ°•μλ” HMMμ μ„Έ λ²μ§Έ λ¬Έμ μΈ **Learning Problem**μ„ λ‹¤λ£¬λ‹¤. κ΄€μΈ΅ λ°μ΄ν„°λ§ μ£Όμ–΄μ΅μ„ λ• HMMμ νλΌλ―Έν„°λ¥Ό μ¶”μ •ν•κΈ° μ„ν•΄ μ‚¬μ©ν•λ” μ•κ³ λ¦¬μ¦μ΄ λ°”λ΅ **Baumβ€“Welch Algorithm**μ΄λ©°, μ΄λ” **EM Algorithm (Expectationβ€“Maximization)**μ ν• μΆ…λ¥μ΄λ‹¤.

---

## 2. HMMμ μ„Έ κ°€μ§€ λ¬Έμ  λ³µμµ
1. **Problem 1. Evaluation:** κ΄€μΈ΅ μ‹ν€€μ¤ ν™•λ¥  $P(O \mid \lambda)$ κ³„μ‚° $\rightarrow$ Forward / Backward
2. **Problem 2. Decoding:** μµμ  μ€λ‹‰ μƒνƒ κ²½λ΅ μ¶”μ • $\rightarrow$ Viterbi
3. **Problem 3. Learning β­:** κ΄€μΈ΅ λ°μ΄ν„°λ§μΌλ΅ λ¨λΈ νλΌλ―Έν„° $\lambda = (\pi, A, B)$ μ¶”μ •

---

## 3. HMM νλΌλ―Έν„°
<img width="1485" height="943" alt="image" src="https://github.com/user-attachments/assets/8d07564b-3334-4d73-8f4f-5940771d3754" />
<img width="1516" height="715" alt="image" src="https://github.com/user-attachments/assets/d04450be-356e-4151-b617-03371d894b83" />

HMMμ€ λ‹¤μ 3κ°μ νλΌλ―Έν„°λ΅ μ™„μ „ν μ •μλλ‹¤.
$$\lambda = (\pi, A, B)$$

| νλΌλ―Έν„° | μλ―Έ |
| :--- | :--- |
| **$\pi$** | μ΄κΈ° μƒνƒ ν™•λ¥  (Initial Probability) |
| **$A$** | μƒνƒ μ „μ΄ ν™•λ¥  (Transition Probability) |
| **$B$** | λ°©μ¶(κ΄€μΈ΅) ν™•λ¥  (Emission Probability) |

---

## 4. Learning Problemμ ν„μ‹¤μ  μ–΄λ ¤μ›€
μ‹¤μ  λ°μ΄ν„°μ—μ„λ” **μ€λ‹‰ μƒνƒ μ‹ν€€μ¤(Hidden state sequence)** μ •λ³΄κ°€ μ—†λ‹¤. μ¤μ§ **κ΄€μΈ΅ μ‹ν€€μ¤(Observation sequence)**λ§ μ΅΄μ¬ν•κΈ° λ•λ¬Έμ—, λ‹¨μν λ°μƒ νμλ¥Ό μΉ΄μ΄ν…ν•μ—¬ ν™•λ¥ μ„ κµ¬ν•λ” μ§μ ‘μ μΈ ν•™μµμ΄ λ¶κ°€λ¥ν•λ‹¤.

---

## 5. ν•΄κ²° λ°©λ²•: EM Algorithm
<img width="1340" height="899" alt="image" src="https://github.com/user-attachments/assets/b0eebbe1-9dc6-48d0-8864-5ada2aa0b24f" />
<img width="1493" height="1021" alt="image" src="https://github.com/user-attachments/assets/3f886d2b-0e62-4db8-80f1-0a6a36434dd7" />

Baumβ€“Welch μ•κ³ λ¦¬μ¦μ€ EM μ•κ³ λ¦¬μ¦ κΈ°λ°μ λ°λ³µ μµμ ν™” λ°©λ²•μ΄λ‹¤.



1. **μ΄κΈ° νλΌλ―Έν„° μ„¤μ •**
2. **E-step (Expectation):** ν„μ¬ νλΌλ―Έν„°λ΅ μ€λ‹‰ μƒνƒμ— λ€ν• κΈ°λ“κ°’(ν™•λ¥ ) κ³„μ‚°
3. **M-step (Maximization):** κ³„μ‚°λ ν™•λ¥ μ„ λ°”νƒ•μΌλ΅ νλΌλ―Έν„° μ—…λ°μ΄νΈ
4. **μλ ΄**ν•  λ•κΉμ§€ λ°λ³µ

---

## 6. E-step (Expectation Step)
ν„μ¬ νλΌλ―Έν„°λ¥Ό μ΄μ©ν•΄ λ‘ κ°€μ§€ ν•µμ‹¬ ν™•λ¥ μΈ **$\gamma$(Gamma)**μ™€ **$\xi$(Xi)**λ¥Ό κ³„μ‚°ν•λ‹¤.
<img width="1491" height="832" alt="image" src="https://github.com/user-attachments/assets/d4fdbd67-7a55-41e7-a798-594349ef12d9" />

### β… Gamma ($\gamma$)
- **μλ―Έ:** μ‹κ°„ $t$μ—μ„ μ€λ‹‰ μƒνƒκ°€ $i$μΌ ν™•λ¥ 
$$\gamma_t(i) = P(q_t = i \mid O, \lambda) = \frac{\alpha_t(i)\beta_t(i)}{\sum_{j=1}^N \alpha_t(j)\beta_t(j)}$$
<img width="1475" height="978" alt="image" src="https://github.com/user-attachments/assets/58f1bec3-39b8-43dc-9677-bdbd33d5085a" />

### β… Xi ($\xi$)
- **μλ―Έ:** μ‹κ°„ $t$μ— μƒνƒ $i$μ΄κ³ , $t+1$ μ‹μ μ— μƒνƒ $j$μΌ ν™•λ¥ 
$$\xi_t(i,j) = P(q_t=i, q_{t+1}=j \mid O, \lambda) = \frac{\alpha_t(i) a_{ij} b_j(O_{t+1}) \beta_{t+1}(j)}{P(O \mid \lambda)}$$
<img width="1480" height="840" alt="image" src="https://github.com/user-attachments/assets/d058e6b8-e140-4ea5-80c1-6b8f7d3e74fc" />

<img width="1476" height="912" alt="image" src="https://github.com/user-attachments/assets/60cc44ab-6b3b-4100-ad62-2d682c7f9356" />


---

## 7. $\alpha$ μ™€ $\beta$μ μ—­ν• 
- **$\alpha$ (Forward):** κ³Όκ±°μ—μ„ ν„μ¬κΉμ§€μ ν™•λ¥  λ„μ 
- **$\beta$ (Backward):** λ―Έλμ—μ„ ν„μ¬λ΅μ ν™•λ¥  μ΅°κ±΄λ¶€ κ³„μ‚°
π‘‰ μ΄ λ‘μ΄ λ§λ‚λ” μ§€μ μ—μ„ ν„μ¬ μ‹μ μ μ€λ‹‰ μƒνƒ ν™•λ¥ μ„ λ„μ¶ν•λ‹¤.

---

## 8. M-step (Maximization Step)
E-stepμ—μ„ κµ¬ν• $\gamma, \xi$λ¥Ό μ‚¬μ©ν•μ—¬ νλΌλ―Έν„°λ¥Ό μƒλ΅­κ² μ—…λ°μ΄νΈν•λ‹¤.

### β‘  Initial Probability μ—…λ°μ΄νΈ
<img width="1479" height="813" alt="image" src="https://github.com/user-attachments/assets/70ce9ef4-8b01-4fb7-b24d-7b3051b27f86" />

$$\pi_i^{new} = \gamma_1(i)$$

### β‘΅ Transition Probability μ—…λ°μ΄νΈ
<img width="1500" height="973" alt="image" src="https://github.com/user-attachments/assets/92c310c3-d80a-4bca-ad39-c1f73ca50254" />

$$a_{ij}^{new} = \frac{\sum_{t=1}^{T-1} \xi_t(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i)}$$
- (λ¶„μ: $i \to j$ μ΄λ™ κΈ°λ€ νμ) / (λ¶„λ¨: $i$ μƒνƒμ— μμ—λ μ „μ²΄ κΈ°λ€ νμ)

### β‘Ά Emission Probability μ—…λ°μ΄νΈ
<img width="1465" height="854" alt="image" src="https://github.com/user-attachments/assets/9baad89b-2cf0-47dc-b633-6a2988a1e77c" />

$$b_i(k)^{new} = \frac{\sum_{t:O_t=k} \gamma_t(i)}{\sum_{t=1}^{T} \gamma_t(i)}$$
- ($i$ μƒνƒμ—μ„ κ΄€μΈ΅ $k$κ°€ λ‚μ¨ νμ) / ($i$ μƒνƒμ μ „μ²΄ νμ)

<img width="992" height="484" alt="image" src="https://github.com/user-attachments/assets/342c6729-1db9-447a-9671-8d08dfb3b3ae" />

---

## 9. μ „μ²΄ Baumβ€“Welch μ•κ³ λ¦¬μ¦ νλ¦„
1. νλΌλ―Έν„° $(\pi, A, B)$ λ¬΄μ‘μ„ μ΄κΈ°ν™”
2. **E-step:** Forward($\alpha$) & Backward($\beta$) μν–‰ ν›„ $\gamma, \xi$ κ³„μ‚°
3. **M-step:** $\pi, A, B$ μ—…λ°μ΄νΈ
4. **λ΅κ·Έμ°λ„(Log-likelihood)** μ¦κ°€ ν™•μΈ
5. μλ ΄ μ΅°κ±΄ λ§μ΅± μ‹κΉμ§€ λ°λ³µ

---

## 10. μλ ΄ μ΅°κ±΄ (Stopping Rule)
<img width="1491" height="937" alt="image" src="https://github.com/user-attachments/assets/33f8e09d-3e49-4900-aea0-556b539b3ec6" />

- λ΅κ·Έμ°λ„ μ¦κ°€λ‰ < $\epsilon$
- λ°λ³µ νμ(Epoch) λ„λ‹¬
- νλΌλ―Έν„° λ³€ν™”λ‰ < μ„κ³„κ°’(threshold)

---

## 11. Baumβ€“Welchμ νΉμ§•
- **Local Optimum:** ν•­μƒ μ „μ—­ μµμ ν•΄λ¥Ό λ³΄μ¥ν•μ§€λ” μ•μΌλ‚ μ§€μ—­ μµμ ν•΄λ΅ μλ ΄ν•λ‹¤.
- **μ΄κΈ°κ°’ λ―Όκ°λ„:** μ΄κΈ° νλΌλ―Έν„° μ„¤μ •μ— λ”°λΌ κ²°κ³Όκ°€ λ‹¬λΌμ§ μ μλ‹¤.
- **Likelihood λ³΄μ¥:** λ°λ³µν•  λ•λ§λ‹¤ Likelihoodλ” λ°λ“μ‹ μ¦κ°€ν•κ±°λ‚ μ μ§€λλ‹¤.

---

## 12. μ‹¤μ  ν™μ© μμ‹
- **Classification:** μ •μƒ/λ¶λ‰ κ³µμ • λ¨λΈμ„ κ°κ° ν•™μµμ‹ν‚¨ ν›„, μƒλ΅μ΄ μ‹ν€€μ¤μ $P(O \mid \lambda)$λ¥Ό λΉ„κµν•μ—¬ λ¶„λ¥ν•λ‹¤.
<img width="1466" height="921" alt="image" src="https://github.com/user-attachments/assets/870863e1-16c8-4a9a-9be3-a3de43e84bfa" />

- **μƒνƒ μ¶”μ •(Decoding):** μλ©΄ λ¶„μ„(EEG μ‹ νΈλ΅ μλ©΄ λ‹¨κ³„ λ³µμ›) λ“±μ— ν™μ©ν•λ‹¤.
<img width="1418" height="926" alt="image" src="https://github.com/user-attachments/assets/74ee8fc5-76f3-4f4e-a911-976a2e7b814d" />

---

## 13. μ „μ²΄ κµ¬μ΅° μ”μ•½
**Hidden Markov Model**
- **Learning:** Baumβ€“Welch (EM)
- **Evaluation:** Forward / Backward
- **Decoding:** Viterbi

β… **μµμΆ… μ”μ•½:** Baumβ€“Welchλ” κ΄€μΈ΅ λ°μ΄ν„°λ§μΌλ΅ HMM νλΌλ―Έν„°λ¥Ό ν•™μµμ‹ν‚¤λ” μ•κ³ λ¦¬μ¦μΌλ΅, EM κΈ°λ°μ λ°λ³µ μµμ ν™”λ¥Ό ν†µν•΄ λ¨λΈμ κ°€λ¥μ„±μ„ μµλ€ν™”ν•λ‹¤.
