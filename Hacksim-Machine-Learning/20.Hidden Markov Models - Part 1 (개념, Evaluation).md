# Hidden Markov Model (HMM) 정리

## 1. 순차 데이터(Sequential Data)
<img width="1340" height="860" alt="image" src="https://github.com/user-attachments/assets/797a4e93-fa4e-4e34-8d29-da049fe4691f" />

### 1.1 순차 데이터란?
**순차 데이터(Sequential Data)**란 순서(order)를 가지는 데이터를 의미한다. 대부분 **시간(time)**의 흐름에 따라 관측되며, 각 데이터 간의 순서가 매우 중요하다.

- **예시:** 센서 데이터, 문장의 단어 순서, 음성 신호, DNA 염기서열
- **표현:** 시퀀스(sequence) 구조
  $$X = (x_1, x_2, \dots, x_T)$$

---

## 2. 순차 데이터의 대표적인 예시
<img width="1315" height="1026" alt="image" src="https://github.com/user-attachments/assets/88b9b69f-73ab-4e15-aaa2-15202519a86e" />

- **DNA 염기서열:** A, T, G, C의 배열 순서 자체가 생물학적 의미를 가짐.
- **제조 공정 데이터:** 설비 사용 흐름(설비 A → 설비 B → 설비 C)이 공정의 품질을 결정함.
- **이미지 필기 데이터:** 펜이 이동하는 방향 시퀀스(↗ → → ↘)로 숫자를 표현 가능함.

---

## 3. Hidden Markov Model (HMM)이란?
<img width="1411" height="781" alt="image" src="https://github.com/user-attachments/assets/e2584f85-3172-4c0d-be05-d238f74bce3f" />

순차 데이터를 확률적으로 모델링하는 대표적인 **생성 모델(Generative Model)**이다.

---

## 4. 왜 Hidden Markov Model 인가?
이 이름은 세 가지 핵심 개념의 결합으로 이루어져 있다.
1. **Hidden (은닉):** 상태를 직접 볼 수 없음.
2. **Markov (마코프):** 상태 변화가 마코프 가정을 따름.
3. **Model (모델):** 이를 확률적으로 정형화함.

---

## 5. Markov Model
### 5.1 상태(State)와 전이
<img width="1415" height="1008" alt="image" src="https://github.com/user-attachments/assets/0706a675-8407-4a33-9bb1-c3c4725a6872" />
<img width="1472" height="862" alt="image" src="https://github.com/user-attachments/assets/b2983a15-84bb-401c-9b8d-dcf9b8631378" />

HMM은 시간에 따라 변화하는 **상태(state)**들의 흐름이다.
- **예시:** 날씨 $S = \{\text{비, 맑음}\}$
- **상태 시퀀스:** 비 → 맑음 → 맑음 → 비

### 5.2 상태 전이 확률 행렬 ($A$)
<img width="1457" height="801" alt="image" src="https://github.com/user-attachments/assets/7466ddc5-9493-421d-ad45-0155d8581f12" />

상태가 $i$에서 $j$로 변할 확률을 행렬로 나타낸 것이다. 각 행의 합은 1이다.
$$A = \begin{bmatrix} P(\text{비} \to \text{비}) & P(\text{비} \to \text{맑음}) \\ P(\text{맑음} \to \text{비}) & P(\text{맑음} \to \text{맑음}) \end{bmatrix}$$

---

## 6. Markov 가정 (Markov Assumption)
현재 상태는 **바로 이전 상태**에만 의존한다는 가정이다.
$$P(S_t \mid S_{t-1}, S_{t-2}, \dots, S_1) = P(S_t \mid S_{t-1})$$
👉 이를 **1차 마코프 과정(First-order Markov Process)**이라고 한다.

---

## 7. Hidden의 의미
현실에서는 상태(날씨)는 보이지 않고, 그 상태에 의한 결과(사람의 행동)만 관측되는 경우가 많다.

- **Hidden State (은닉 상태):** 날씨 (비, 맑음)
- **Observable State (관측 상태):** 행동 (산책, 쇼핑, 연구)



---

## 8. Hidden Markov Model 구조
<img width="1405" height="880" alt="image" src="https://github.com/user-attachments/assets/58fb068f-cac5-4366-85f2-2d2fe88e413e" />
<img width="1488" height="856" alt="image" src="https://github.com/user-attachments/assets/8004d2bc-6f4a-4d8e-965b-e79d68e771ab" />

HMM은 두 개의 상호작용하는 시퀀스를 가진다.
1. **Hidden State Sequence:** $S = (s_1, s_2, \dots, s_T)$ (마코프 성질 만족)
2. **Observation Sequence:** $O = (o_1, o_2, \dots, o_T)$ (은닉 상태에 의존)

---

## 9. HMM의 확률 구조
### 9.1 상태 전이 확률 (Transition Probability)
$$a_{ij} = P(s_{t+1}=j \mid s_t=i)$$

### 9.2 관측(방출) 확률 (Emission Probability)
$$b_j(k) = P(o_t = k \mid s_t = j)$$
👉 특정 은닉 상태에서 특정 관측값이 나올 확률이다.

### 9.3 초기 상태 확률 (Initial Probability)
$$\pi_i = P(s_1 = i)$$

---

## 10. HMM의 파라미터
<img width="1532" height="1118" alt="image" src="https://github.com/user-attachments/assets/bbf46758-a5bd-4b2c-b45f-0665dc809efc" />
<img width="1501" height="867" alt="image" src="https://github.com/user-attachments/assets/ed4ba03f-e7ba-44ea-b7ac-40ad53bd7dcb" />

HMM은 세 가지 파라미터 묶음 $\lambda$로 완전히 정의된다.
$$\lambda = (A, B, \pi)$$

| 기호 | 의미 |
| :--- | :--- |
| **$A$** | 상태 전이 확률 행렬 |
| **$B$** | 관측(방출) 확률 행렬 |
| **$\pi$** | 초기 상태 확률 |

---

## 11. HMM의 대표적인 적용 예
<img width="1481" height="759" alt="image" src="https://github.com/user-attachments/assets/a252f207-7f84-48ac-ba85-33f53d7823ec" />

- **날씨–행동 모델:** 날씨(Hidden)에 따른 사람의 활동(Observation) 예측
- **동전 상자 문제:** 선택된 상자(Hidden)에 따른 앞/뒷면(Observation) 확률
- **DNA 유전자 예측:** 유전자 구간 여부(Hidden)에 따른 염기서열(Observation)
- **품사 태깅 (POS Tagging):** 품사(Hidden)에 따른 단어(Observation) 배열

---

## 12. HMM의 세 가지 핵심 문제
<img width="1475" height="1049" alt="image" src="https://github.com/user-attachments/assets/a9a041f9-f354-456e-a2da-a545f7d66aea" />

### ① Evaluation (평가)
주어진 모델에서 특정 관측 시퀀스가 발생할 확률 $P(O \mid \lambda)$은?
👉 **Forward / Backward Algorithm**

### ② Decoding (해독)
관측 시퀀스가 주어졌을 때 가장 가능성 높은 은닉 상태 시퀀스 $\arg\max_S P(S \mid O, \lambda)$는?
👉 **Viterbi Algorithm**

### ③ Learning (학습)
관측 데이터만으로 모델 파라미터 $(A, B, \pi)$를 어떻게 최적화할 것인가?
👉 **Baum–Welch Algorithm (EM 알고리즘)**

---

## 13. 요약
- HMM은 순차 데이터를 위한 확률적 생성 모델이다.
- 마코프 가정을 따르는 은닉 상태와 그에 의존하는 관측 시퀀스로 구성된다.
- 파라미터 $\lambda = (A, B, \pi)$를 통해 모델의 모든 특성이 결정된다.

---

# Hidden Markov Model (HMM) – Forward / Backward 알고리즘 정리

## 1. Hidden Markov Model 개요
히든 마르코프 모델(Hidden Markov Model, HMM)은
관측 가능한 시퀀스(observation) 와
직접 관측할 수 없는 은닉 상태(hidden state)
사이의 확률적 관계를 모델링하는 확률 그래프 모델이다.

---

## 2. HMM의 구성 요소
HMM은 다음 5가지로 정의된다.
<img width="1472" height="875" alt="image" src="https://github.com/user-attachments/assets/e715998a-baf1-4dad-9782-58368e2318d6" />

**(1) Hidden States**
보이지 않는 상태
예시: 비(Rain), 해(Sunny)

**(2) Observation States**
실제로 관측되는 값
예시: 산책(Walk), 연구(Study), 쇼핑(Shop)

**(3) Initial State Probability (초기 확률)**
$$\pi_i = P(q_1 = i)$$
예시:
- Rain : 0.6
- Sunny: 0.4

**(4) Transition Probability (상태 전이 확률)**
$$A = a_{ij} = P(q_{t+1}=j \mid q_t=i)$$

| From \ To | Rain | Sunny |
| :--- | :--- | :--- |
| **Rain** | 0.7 | 0.3 |
| **Sunny** | 0.4 | 0.6 |

**(5) Emission Probability (방출 확률)**
$$B = b_j(o_t) = P(O_t=o_t \mid q_t=j)$$

| State | Walk | Study | Shop |
| :--- | :--- | :--- | :--- |
| **Rain** | 0.1 | 0.4 | 0.5 |
| **Sunny** | 0.6 | 0.3 | 0.1 |

---

## 3. HMM의 세 가지 핵심 문제
- **Problem 1. Evaluation (확률 계산 문제):** 관측 시퀀스가 주어졌을 때 확률은? $$P(O_1, O_2, \dots, O_T \mid \lambda)$$
- **Problem 2. Decoding (디코딩 문제):** 관측 시퀀스를 만들어낸 가장 가능성 높은 hidden state sequence는? → **Viterbi Algorithm** 사용
- **Problem 3. Learning (학습 문제):** 모델 파라미터($\pi, A, B$)를 어떻게 학습할 것인가? → **Baum-Welch Algorithm (EM Algorithm)**

🚩 **이번 강의 핵심: Problem 1 – Evaluation**

---

## 4. Evaluation 문제의 어려움
<img width="1511" height="1105" alt="image" src="https://github.com/user-attachments/assets/5b667484-9483-4bca-9a61-685ba608266d" />

관측 시퀀스 예시: $O = [\text{산책, 산책, 연구, 쇼핑}]$
Hidden state가 $N$개, 시퀀스 길이 $T$이면 경우의 수는 $N^T$이다.
예시: $N = 3, T = 20 \rightarrow 3^{20} \approx 35\text{억 가지 경우}$
❌ **전부 계산하는 것은 불가능함.**

---

## 5. 해결 방법: Dynamic Programming
핵심 아이디어: 모든 경우를 다 보지 말고 **이전 시점의 확률만 재사용하자.**



이 개념이 바로 **Forward Algorithm**과 **Backward Algorithm**이다.

---

## 🔵 Forward Algorithm
<img width="1260" height="545" alt="image" src="https://github.com/user-attachments/assets/ced3f45c-dda2-4bb3-b16e-071cbf80f1ea" />
<img width="1308" height="564" alt="image" src="https://github.com/user-attachments/assets/fb98d19f-a42b-41b8-8dc0-0aed36a452b8" />
<img width="1330" height="575" alt="image" src="https://github.com/user-attachments/assets/c0b0a317-e6dd-4f14-be52-fc84075a7d19" />
<img width="1500" height="1020" alt="image" src="https://github.com/user-attachments/assets/e90b8553-ba83-4f17-8b06-f2840880a93e" />

### 6. Forward Probability 정의
$\alpha_t(i)$의 의미: 시간 $t$에서 상태 $i$에 있으면서 지금까지의 관측 시퀀스가 발생할 확률
$$\alpha_t(i) = P(O_1, O_2, \dots, O_t, q_t=i \mid \lambda)$$

### 7. Forward Algorithm 절차
<img width="1478" height="910" alt="image" src="https://github.com/user-attachments/assets/acc74e4f-18dd-4411-bd2d-3609d0932ac5" />

- **Step 1. Initialization:** $$\alpha_1(i) = \pi_i \cdot b_i(O_1)$$
- **Step 2. Recursion:** $$\alpha_t(j) = \left( \sum_i \alpha_{t-1}(i)a_{ij} \right)b_j(O_t)$$
- **Step 3. Termination:** $$P(O \mid \lambda) = \sum_i \alpha_T(i)$$

### 8. Forward Algorithm 핵심 포인트
- 이전 시점의 확률만 사용하지만, 그 안에는 모든 과거 경로 정보가 포함됨.
- 계산 복잡도: $O(N^2 T)$ (지수 시간 → 다항 시간으로 단축)

---
<img width="1396" height="837" alt="image" src="https://github.com/user-attachments/assets/4c06a494-76d4-459f-aba7-486c7467b127" />

## 🔴 Backward Algorithm
<img width="1497" height="749" alt="image" src="https://github.com/user-attachments/assets/6d23ca2c-c9db-4f7f-b8a2-156189b30a24" />
<img width="1468" height="566" alt="image" src="https://github.com/user-attachments/assets/035b02ea-f71f-4bde-b278-977241e13239" />
<img width="1485" height="615" alt="image" src="https://github.com/user-attachments/assets/8775221d-f620-49dc-aec9-dccb013596fc" />
<img width="1425" height="600" alt="image" src="https://github.com/user-attachments/assets/e19fa100-b793-4019-8a5d-13ab54b3499c" />

### 9. Backward Probability 정의
$\beta_t(i)$의 의미: 시간 $t$에서 상태 $i$일 때 남은 관측 시퀀스가 발생할 확률
$$\beta_t(i) = P(O_{t+1}, \dots, O_T \mid q_t=i, \lambda)$$

### 10. Backward Algorithm 절차
- **Step 1. Initialization:** $$\beta_T(i) = 1$$
- **Step 2. Recursion:** $$\beta_t(i) = \sum_j a_{ij} b_j(O_{t+1}) \beta_{t+1}(j)$$
- **Step 3. Termination:** $$P(O \mid \lambda) = \sum_i \pi_i b_i(O_1) \beta_1(i)$$

---

## 11. Forward vs Backward 비교
<img width="1429" height="797" alt="image" src="https://github.com/user-attachments/assets/39e9c906-3554-447d-934f-56d3b13536d1" />
<img width="1502" height="1111" alt="image" src="https://github.com/user-attachments/assets/d86e5baa-611b-46aa-be38-566401780fe9" />

| 구분 | Forward | Backward |
| :--- | :--- | :--- |
| **방향** | 좌 → 우 | 우 → 좌 |
| **기호** | $\alpha$ | $\beta$ |
| **결과** | 동일한 확률 | 동일한 확률 |
| **용도** | Evaluation | Learning (EM) |

---

## 12. 중요한 사실
$$\sum_i \alpha_T(i) = \sum_i \pi_i b_i(O_1) \beta_1(i)$$
✔ **반드시 동일해야 한다.**

---

## 13. 응용 예시: Classification
서로 다른 두 모델(예: 모델 A, 모델 B)이 있을 때 같은 관측 시퀀스 $O$에 대해:
- $P(O \mid \lambda_A) = 0.78$
- $P(O \mid \lambda_B) = 0.55$
→ 해당 시퀀스는 모델 A에서 나왔을 가능성이 높다.

---

## 🔥 핵심 요약
- HMM은 보이지 않는 상태를 확률적으로 추론하는 모델이다.
- Evaluation 문제는 관측 시퀀스의 확률 계산이다.
- 모든 경우의 수 계산은 불가능하므로 해결책으로 **Dynamic Programming**을 사용한다.
  - **Forward Algorithm**: 과거 → 현재
  - **Backward Algorithm**: 미래 → 현재
- 두 방법은 동일한 확률을 계산한다.

👉 **다음 강의 예고:** Decoding Problem (Viterbi Algorithm)
