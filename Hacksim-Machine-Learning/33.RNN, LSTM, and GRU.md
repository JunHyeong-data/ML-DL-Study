# RNN 학습 과정과 한계 (상세 정리)

---

## 1. RNN의 목적
- 시계열 데이터에서 시점 $t$의 $y$를 예측한다.
- **핵심 아이디어:** 과거의 모든 정보를 활용하는 것이다.
- **문제 유형:** 지도학습 (Supervised Learning)

---

## 2. RNN의 주요 파라미터
RNN에서 학습해야 할 파라미터는 다음 3가지이다.
<img width="1450" height="1078" alt="image" src="https://github.com/user-attachments/assets/1c5631c6-bb3b-49c2-b4ef-b079a5ba5d2d" />

- **(1) $W_{hy}$:** 히든 벡터 $\rightarrow$ 출력 $y$로 변환하는 파라미터. 예측 단계에서 직접 사용된다.
- **(2) $W_{hh}$:** 이전 시점 히든 벡터 $\rightarrow$ 현재 시점 히든 벡터. 시간 축 전이(transition)를 담당하며, 모든 시점에서 **공유(shared)**된다.
- **(3) $W_{xh}$:** 관측치 $x \rightarrow$ 히든 벡터로 변환. 입력 정보를 히든 공간으로 매핑한다.

---

## 3. 히든 벡터 계산식
<img width="1440" height="1098" alt="image" src="https://github.com/user-attachments/assets/77107aa0-67a1-49c4-9d9e-920864bfcfad" />

각 시점 $t$에서 히든 벡터는 다음과 같이 계산된다.
$$h_t = \tanh(W_{xh} x_t + W_{hh} h_{t-1})$$
- 현재 입력($x_t$)과 과거 정보($h_{t-1}$)를 결합한다.
- 활성화 함수로 **$\tanh$**를 사용한다.

---

## 4. 학습의 핵심 개념
- **학습(Training)이란?** 데이터를 이용해 파라미터를 추정하는 과정이다.
- **손실 함수 (Loss Function):** 실제 $y$와 예측 $\hat{y}$의 차이를 측정한다. 
  - 회귀 문제: MSE
  - 분류 문제: Cross-Entropy

---

## 5. 전체 학습 절차 (3단계)
<img width="1437" height="1014" alt="image" src="https://github.com/user-attachments/assets/9dbb5f2b-0a93-4a47-9657-acc85e854d93" />
<img width="1508" height="1067" alt="image" src="https://github.com/user-attachments/assets/a95dda5f-aebb-44e7-96f6-b6b92b1d7644" />
<img width="1395" height="942" alt="image" src="https://github.com/user-attachments/assets/064d47ae-0a8b-44fc-a175-c565d75cabd4" />
<img width="1428" height="906" alt="image" src="https://github.com/user-attachments/assets/45521756-b3e1-412b-8a32-db5c76122272" />
<img width="1414" height="909" alt="image" src="https://github.com/user-attachments/assets/c2d397d3-ee4d-45ce-9aae-c10eb6fe6177" />
<img width="1496" height="876" alt="image" src="https://github.com/user-attachments/assets/663db1c6-5e09-4bdc-a9d2-b4e69e0fd08e" />
<img width="1359" height="941" alt="image" src="https://github.com/user-attachments/assets/dd2b21e4-9405-42ff-a75e-a1ae0604637c" />



- **Step 1. Forward Pass:** 히든 벡터를 계산하고 출력 $y$를 예측한다.
- **Step 2. Loss 계산:** 각 시점의 loss를 계산한다. Many-to-many 구조에서는 시점별 loss의 평균을 낸다.
- **Step 3. Backpropagation:** 비용 함수를 각 파라미터로 미분하여 기울기(Gradient)를 구한다.

---

## 6. Gradient Descent 업데이트
각 파라미터는 경사하강법을 통해 다음과 같이 업데이트된다.
$$W \leftarrow W - \eta \frac{\partial L}{\partial W}$$
- $\eta$: 학습률(Learning Rate)
- Gradient는 비용 함수를 최소화하는 방향을 가리킨다.

---

## 7. BPTT (Backpropagation Through Time)
RNN에서는 시간 축으로 펼쳐서 미분을 수행한다. $W_{hh}$와 $W_{xh}$는 모든 시점의 gradient를 합산하여 업데이트에 반영한다.
$$\frac{\partial L}{\partial W} = \sum_{t} \frac{\partial L_t}{\partial W}$$

---

## 8. RNN의 한계: Vanishing Gradient 문제
- **원인:** $\tanh$의 미분값은 0~1 사이이다. 시계열이 길어질수록 반복적인 곱셈이 발생하여 gradient가 급격히 작아진다.
$$0 < \prod_{k=1}^{T} \tanh'(\cdot) < 1$$



---

## 9. 결과적으로 발생하는 문제
<img width="1495" height="1091" alt="image" src="https://github.com/user-attachments/assets/d53a6e98-0c9b-448c-ba02-051160b5a759" />
<img width="1522" height="1093" alt="image" src="https://github.com/user-attachments/assets/2faddc10-0976-418d-9264-f301dab9a0f2" />

1. **Gradient 소실 (Vanishing Gradient):** 과거 시점으로 갈수록 파라미터가 거의 업데이트되지 않는다.
2. **장기 의존성 문제 (Long-Term Dependency Problem):** 먼 과거의 정보를 현재 예측에 반영하기 어려워지며, 입력층 근처의 파라미터 학습이 실패하게 된다.

---

## 10. 요약
- RNN은 과거 정보를 누적해 예측하는 모델이다.
- BPTT로 학습하지만, **Vanishing Gradient** 문제로 인해 긴 시계열의 장기 의존성을 학습하는 데 한계가 있다.
- 이 한계를 극복하기 위해 **LSTM, GRU** 같은 게이트 구조가 등장했다.

📘 본 문서는 강의 내용을 수식과 핵심 개념 중심으로 재구성한 마크다운 정리 노트입니다.

---
# RNN → LSTM → GRU : 히든 스테이트를 구하는 방법의 진화

---

## 1. 문제의 출발점: RNN의 한계
RNN의 핵심은 단 하나이다. **"$t$ 시점의 히든 스테이트($h_t$)를 어떻게 만들 것인가?"**이다.

일반 RNN은 다음과 같이 정의된다.
$$h_t = \tanh(W_x x_t + W_h h_{t-1} + b)$$
- 현재 입력($x_t$)과 이전 히든 스테이트($h_{t-1}$)를 가중합하여 비선형 함수를 통과시킨다.
- **문제 발생:** 시간 축으로 역전파(BPTT) 수행 시 미분값이 반복해서 곱해지며 기울기 소실(Vanishing Gradient)이 발생한다. 이로 인해 오래된 과거 정보가 학습되지 않는 **장기 의존성 문제**가 나타난다.

---

## 2. LSTM의 핵심 아이디어
<img width="1506" height="1052" alt="image" src="https://github.com/user-attachments/assets/7714bc75-dc90-4b92-a245-2014410fa8b5" />
<img width="594" height="195" alt="image" src="https://github.com/user-attachments/assets/0a9f7422-4138-4ebe-9dfe-741dae0ce323" />
<img width="519" height="195" alt="image" src="https://github.com/user-attachments/assets/83643f62-709b-4a19-88a0-62d8df26086b" />

LSTM은 질문을 이렇게 바꾼다. 
> **“과거 정보를 무조건 쓰지 말고, 쓸지 / 버릴지 / 얼마나 쓸지를 학습으로 결정하자”**

이를 위해 두 가지 핵심 장치를 도입한다.
1. **Cell State ($c_t$):** 장기 기억 전용 통로
2. **Gate 구조:** 정보의 흐름을 조절하는 스위치



---

## 3. LSTM의 구성 요소
- **(1) Cell State ($c_t$):** 시간 축을 따라 흐르는 장기 기억 벡터이다. 덧셈 구조 중심이라 기울기 보존에 유리하며 "기억 저장소" 역할을 한다.
- **(2) Hidden State ($h_t$):** 외부 출력 및 다음 시점 계산에 사용된다. 최종적으로 예측에 사용하는 벡터이다.

---

## 4. LSTM의 3가지 게이트 (모두 벡터)

<img width="1463" height="1046" alt="image" src="https://github.com/user-attachments/assets/e0698d60-bf38-450a-8d36-55affa20151b" />
<img width="1492" height="963" alt="image" src="https://github.com/user-attachments/assets/e750611f-42e9-4986-9476-606c502fa634" />
<img width="1516" height="1081" alt="image" src="https://github.com/user-attachments/assets/0405416f-57de-456c-8de8-84fcf21c4198" />
<img width="1503" height="1078" alt="image" src="https://github.com/user-attachments/assets/b41c96f1-2c90-4356-9719-d3b1237c6e03" />
<img width="1498" height="1094" alt="image" src="https://github.com/user-attachments/assets/a74f5ddf-d2ff-4220-bb9e-a39ba71d92b1" />
<img width="1514" height="1082" alt="image" src="https://github.com/user-attachments/assets/f918af87-a62a-4be9-9b6b-6fdb3d7b5ce1" />
<img width="1523" height="1071" alt="image" src="https://github.com/user-attachments/assets/d73430cb-d469-42e1-a4f4-30273fdf7009" />
<img width="1510" height="1067" alt="image" src="https://github.com/user-attachments/assets/78b75466-4cfc-4e2d-aa72-f2d0006d4221" />
<img width="1494" height="1061" alt="image" src="https://github.com/user-attachments/assets/4032fe69-74db-4ba2-8cec-61d4d4f46876" />
<img width="1488" height="1065" alt="image" src="https://github.com/user-attachments/assets/f208ed77-d0a7-45eb-a0a0-5f2ded4b3055" />

모든 게이트는 $0 \sim 1$ 사이의 값을 출력하는 시그모이드($\sigma$) 함수를 사용한다.

- **① Forget Gate ($f_t$):** 과거 정보를 얼마나 남길 것인가?
  $$f_t = \sigma(W_f x_t + U_f h_{t-1} + b_f)$$
- **② Input Gate ($i_t$):** 현재 정보를 얼마나 새로 저장할 것인가?
  $$i_t = \sigma(W_i x_t + U_i h_{t-1} + b_i)$$
- **③ Output Gate ($o_t$):** 셀 상태 중 어떤 정보를 출력할 것인가?
  $$o_t = \sigma(W_o x_t + U_o h_{t-1} + b_o)$$

---

## 5. 임시 셀 스테이트 (Candidate Cell State)
현재 시점에서 새롭게 만들어지는 정보의 후보군이다.
$$\tilde{c}_t = \tanh(W_c x_t + U_c h_{t-1} + b_c)$$
- 게이트 없이 현재 입력이 만들어낸 정보의 초안이다.

---

## 6. Cell State 업데이트 (LSTM의 핵심)
$$c_t = f_t \odot c_{t-1} + i_t \odot \tilde{c}_t$$
- **의미:** $(f_t \odot c_{t-1})$은 과거 정보를 조절하고, $(i_t \odot \tilde{c}_t)$은 현재 정보를 조절한다. 
- $\odot$은 원소별 곱(element-wise product)을 의미하며, 과거와 현재 정보를 가중합으로 결합한다.



---

## 7. Hidden State 계산 (최종 목표)
$$h_t = o_t \odot \tanh(c_t)$$
- 셀 상태를 비선형 변환한 후 출력 게이트로 한 번 더 필터링한다. 이 $h_t$가 다음 시점으로 전달되고 최종 예측($y_t = W_y h_t$)에 사용된다.

---

## 8. 왜 LSTM은 기울기 소실을 줄이는가?
핵심은 **Cell State의 덧셈 구조**이다. 활성화 함수를 거치지 않고 직접 전달되는 경로가 있어, $f_t \approx 1$인 경우 기울기가 거의 그대로 유지된다. 이를 **Gradient Highway**라고 부른다.

---

## 9. GRU (Gated Recurrent Unit)
<img width="1521" height="1115" alt="image" src="https://github.com/user-attachments/assets/5525693d-5337-4eef-872c-e00f6c8b5d6d" />
<img width="1505" height="968" alt="image" src="https://github.com/user-attachments/assets/88e58c65-092d-4801-9fd5-8b7ea9443a87" />

GRU는 LSTM의 복잡한 구조(많은 파라미터, 느린 학습)를 단순화하기 위해 등장했다.

### 10. GRU의 특징
- Cell State가 없으며 Hidden State 하나로 기억을 표현한다.
- 게이트를 3개에서 2개로 줄였다.
  - **Update Gate ($z_t$):** 과거 vs 현재 비율 결정
  - **Reset Gate ($r_t$):** 과거 정보 무시 정도 결정

---

## 11. GRU 수식 구조
- **(1) Update Gate:** $z_t = \sigma(W_z x_t + U_z h_{t-1})$
- **(2) Reset Gate:** $r_t = \sigma(W_r x_t + U_r h_{t-1})$
- **(3) Candidate Hidden State:** $\tilde{h}_t = \tanh(W_h x_t + U_h (r_t \odot h_{t-1}))$
- **(4) Hidden State 업데이트:** $$h_t = (1 - z_t) \odot h_{t-1} + z_t \odot \tilde{h}_t$$



---

## 12. RNN / LSTM / GRU 비교 요약

| 항목 | RNN | LSTM | GRU |
| :--- | :--- | :--- | :--- |
| **장기 의존성** | 약함 | 강함 | 강함 |
| **Gate 수** | 없음 | 3개 | 2개 |
| **Cell State** | 없음 | 있음 | 없음 |
| **파라미터** | 적음 | 많음 | 중간 |

---

## 13. 최종 핵심 정리
- **공통 목표:** $h_t$를 잘 구하는 것.
- **RNN:** 단순하지만 장기 기억 실패.
- **LSTM:** 게이트와 셀 상태를 도입하여 장기 기억 성공.
- **GRU:** LSTM을 단순화한 실용적인 대안.

📘 본 문서는 강의 내용을 수식과 핵심 개념 중심으로 재구성한 마크다운 정리 노트입니다.
