# 군집분석(Clustering) 정리

---

## 1. 군집분석이란?
<img width="1428" height="927" alt="image" src="https://github.com/user-attachments/assets/d8fee6e9-aa76-4df4-b6d2-9ba7c8915c00" />

군집분석(Clustering)이란 **예측을 목적**으로 하는 모델이 아니라,

> **주어진 관측치들 사이의 유사성을 기준으로 비슷한 데이터끼리 묶는 비지도 학습 방법**

을 의미한다.

### ✅ 군집분석의 핵심 목적
<img width="1411" height="1043" alt="image" src="https://github.com/user-attachments/assets/6588ec7b-8d5b-42c5-a516-520411e3fb08" />

- **같은 군집 내 데이터**
  - 서로 최대한 **유사**해야 함
- **서로 다른 군집 간 데이터**
  - 최대한 **다르게(멀리)** 위치해야 함

즉,
- 군집 내부 → **Compact (조밀하게)**
- 군집 간 거리 → **Separated (멀리 떨어지게)**



---

## 2. 분류(Classification)와 군집(Clustering)의 차이
<img width="1424" height="965" alt="image" src="https://github.com/user-attachments/assets/659eb413-f690-4e51-9ab6-f009f4f9b0f0" />

| 구분 | 분류 | 군집 |
| :--- | :--- | :--- |
| **학습 유형** | 지도학습 | 비지도학습 |
| **타깃 변수** | 존재 (y 있음) | 없음 (y 없음) |
| **목적** | 예측 | 구조 파악 |
| **기준** | 결정 경계 (Decision Boundary) | 유사도 |

### 분류 예시
- 입력 변수 $X$를 이용해 범주형 $y$를 예측
- 새로운 데이터가 들어오면 **어느 클래스에 속하는지 예측**

### 군집 예시
- $y$가 존재하지 않음
- 단순히 **비슷한 관측치끼리 묶음**
- 군집 경계는 **결정경계가 아님**

---

## 3. 군집분석의 활용 사례

### 1️⃣ 고객 세분화(Customer Segmentation)
- 백화점, 이동통신사, 카드사 등에서 비슷한 소비 패턴이나 이용 성향을 가진 고객끼리 군집화하여 **마케팅 효율 향상**

### 2️⃣ 문서 군집(Document Clustering)
- 뉴스 기사, 특허, 논문 등을 단어 분포나 특징을 기반으로 스포츠, 정치 등으로 자동 분류

### 3️⃣ 지역 데이터 군집
- 예: 서울시 구별 오존 농도 측정값 패턴이 비슷한 구끼리 군집화하여 지역적 특성 파악

### 4️⃣ 반도체 웨이퍼 불량 패턴 분석
- 웨이퍼 이미지 데이터를 군집화하여 불량 패턴(상단 집중, 가장자리 집중 등) 파악 및 공정 이상 원인 분석에 활용

---

## 4. 군집분석 시 고려사항
<img width="1360" height="981" alt="image" src="https://github.com/user-attachments/assets/1a58abbb-a3d4-4ad3-963d-d5d8a536a7cc" />

군집분석을 수행할 때 주요 고려 요소는 다음과 같다.
1. **유사도(거리)의 정의**
2. **군집 알고리즘 선택**
3. **군집 개수 결정**
4. **군집 결과 평가**

---

## 5. 유사도와 거리 개념

- 유사도 $\uparrow$ → 거리 $\downarrow$
- 거리 $\uparrow$ → 유사도 $\downarrow$

> 군집분석에서는 **거리(distance)** 를 이용해 유사도를 계산한다.

---

## 6. 주요 거리 측정 방법

### 6.1 유클리드 거리 (Euclidean Distance)
<img width="1416" height="780" alt="image" src="https://github.com/user-attachments/assets/bae1a5c4-48b9-4629-95b1-20dcb060d590" />

$$d(x, y) = \sqrt{\sum_{i=1}^{p}(x_i - y_i)^2}$$
- 가장 기본적인 거리 (L2 norm), 직선 최단거리

### 6.2 맨해튼 거리 (Manhattan Distance)
<img width="1368" height="936" alt="image" src="https://github.com/user-attachments/assets/692f7e3f-d1d4-4298-b13c-4ed84ed3312e" />

$$d(x, y) = \sum_{i=1}^{p}|x_i - y_i|$$
- 격자 구조 이동 거리 (L1 norm)

### 6.3 마할라노비스 거리 (Mahalanobis Distance)
<img width="1413" height="849" alt="image" src="https://github.com/user-attachments/assets/4550622e-c1e2-4593-98a8-8a4f4f32d49d" />
<img width="1332" height="897" alt="image" src="https://github.com/user-attachments/assets/eb254834-8fd2-46f6-8b2b-122a36991dac" />

$$d(x, y) = \sqrt{(x-y)^T \Sigma^{-1} (x-y)}$$
- 공분산 행렬($\Sigma$)을 고려하여 변수 간 상관관계를 반영한 타원 형태 거리

### 6.4 상관계수 거리 (Correlation Distance)
<img width="1449" height="919" alt="image" src="https://github.com/user-attachments/assets/01ea80d9-dd6d-4bbd-9bec-dfe8f88643dc" />

$$d = 1 - \text{correlation}$$
- 패턴이 비슷하면 수직적 차이가 커도 거리가 작음 (범위: 0 ~ 2)

### 6.5 스피어만 상관계수 거리
<img width="1445" height="878" alt="image" src="https://github.com/user-attachments/assets/9708bacb-6a99-47e7-b0b9-b41f718b999e" />
<img width="1495" height="909" alt="image" src="https://github.com/user-attachments/assets/6a5070c8-7711-402f-a7c0-2cebeba73074" />

- 데이터 크기보다 **패턴의 순위(rank)** 가 중요할 때 사용

---

## 7. 군집 알고리즘의 종류
<img width="1471" height="1085" alt="image" src="https://github.com/user-attachments/assets/6f984b93-e14d-45f2-ac85-43f0e872bdbe" />
<img width="1470" height="1055" alt="image" src="https://github.com/user-attachments/assets/885858bf-6a69-493c-88b1-20eda9813ff8" />

1. **계층적 군집화 (Hierarchical)**
2. **분리형 군집화 (Partitioning)**
3. **자기조직화 지도 (SOM)**
4. **분포 기반 군집화 (Model-based)**

본 강의에서는 **계층적 군집화**와 **분리형 군집화**를 중심으로 다룸.

---

## 8. 계층적 군집화 (Hierarchical Clustering)
<img width="1459" height="1097" alt="image" src="https://github.com/user-attachments/assets/b4074824-a645-4c9e-9708-9e1784169a30" />

### 특징
- 데이터를 하나씩 병합하거나 분리하여 트리 구조 생성
- 결과를 **덴드로그램(Dendrogram)** 으로 표현

### 덴드로그램(Dendrogram)
- 나무(tree) 형태 구조 (y축: 거리, x축: 관측치)
- ❗ 결정트리와의 차이점: 결정트리는 $y$를 사용하지만, 덴드로그램은 $y$ 없이 거리 기반으로 생성됨



---

## 9. 계층적 군집화 과정 예시
<img width="1476" height="883" alt="image" src="https://github.com/user-attachments/assets/c8d730c5-ff6c-4842-9ea4-c897435b2fda" />
<img width="1461" height="892" alt="image" src="https://github.com/user-attachments/assets/3ef7492f-4cac-4fe1-9db0-56593f461019" />
<img width="1496" height="885" alt="image" src="https://github.com/user-attachments/assets/24967bb6-164c-41c5-8050-ebc75393d1b5" />
<img width="1458" height="876" alt="image" src="https://github.com/user-attachments/assets/81dabc34-c447-41e8-8a3a-2f0e6baadc86" />

1. **거리 행렬 계산:** 모든 관측치 간 거리 계산
2. **병합:** 가장 가까운(거리 최소) 두 관측치를 하나의 군집으로 묶음
3. **군집 간 거리 계산:** 군집과 군집 사이의 거리를 계산하는 기준 설정 필요

---

## 10. 군집 간 거리 계산 방법 (Linkage)
<img width="1455" height="1057" alt="image" src="https://github.com/user-attachments/assets/a7795d33-4e80-4203-930b-4841846e2d13" />

- **Single Linkage (최소 거리):** 가장 가까운 두 점 사이의 거리
- **Complete Linkage (최대 거리):** 가장 먼 두 점 사이의 거리
- **Average Linkage (평균 거리):** 모든 쌍의 평균 거리
- **Centroid Linkage:** 각 군집의 중심점(Centroid) 간 거리

---

## 11. Ward 방법 (Ward’s Method)
<img width="1478" height="1027" alt="image" src="https://github.com/user-attachments/assets/c98d52d7-e53e-4904-a7dc-ac9fb8fdafea" />
가장 많이 사용되는 계층적 군집 거리 기준이다.

### 핵심 아이디어
> 두 군집을 합쳤을 때 **군집 내 분산 증가량(SSE)** 이 최소가 되도록 병합

### 수식 개념
$$D(A,B) = \sum_{i \in A \cup B} \|x_i - \mu_{A \cup B}\|^2 - \left( \sum_{i \in A} \|x_i - \mu_A\|^2 + \sum_{i \in B} \|x_i - \mu_B\|^2 \right)$$

### 해석
- 두 군집을 합쳤을 때 내부 퍼짐이 작게 증가하면 가깝다고 판단하여 병합함
- 결과적으로 **컴팩트한 군집**을 생성하는 경향이 있음

---

## 12. 요약

- 군집분석은 정답($y$)이 없는 **비지도 학습**이다.
- 유사도(거리) 정의에 따라 결과가 크게 달라지므로 적절한 거리 척도 선택이 중요하다.
- 계층적 군집화의 Ward 방법은 군집 내 동질성을 확보하기 좋아 가장 안정적이다.

---
📘 본 문서는 강의 내용을 수식과 핵심 개념 중심으로 재구성한 마크다운 정리 노트입니다.

---
# K-means 군집화 (K-means Clustering)

---

## 1. K-means 군집화란?
<img width="1486" height="1041" alt="image" src="https://github.com/user-attachments/assets/d70471e5-7266-4038-9c91-108739920a28" />

K-means 군집화는 **분리형 군집화(Partitioning Clustering)** 의 대표적인 방법이다.

- **비지도 학습(Unsupervised Learning)**
- 타깃 변수 $y$ 없음
- 데이터 $X$만 사용

---

### 핵심 아이디어

> 데이터를 **K개의 군집(cluster)** 으로 나누되  
각 군집의 **평균(mean)** 을 기준으로 군집을 형성한다.

그래서 이름이 **K-means (K-평균)** 이다.



---

## 2. 기호 정리

- $X = \{x_1, x_2, \dots, x_n\}$
  - 전체 데이터 (y 없음)

- $C_1, C_2, \dots, C_K$
  - $K$개의 군집 (cluster)

- 전체 데이터는 다음과 같이 표현됨
$$X = C_1 \cup C_2 \cup \dots \cup C_K$$

### 중요한 성질

- 군집 간 **겹침(overlap) 없음**
- 하나의 관측치는 반드시 **하나의 군집에만 속함**

---

## 3. K-means의 특징

- 군집의 개수 **K를 미리 지정해야 함**
- 어떤 점이 어떤 군집인지 모르지만 **군집의 개수는 알고 시작**한다.

---

### ❓ “군집 개수를 모르는데 왜 군집분석을 하나요?”

실제 문제에서는 정확한 $K$는 몰라도 대략적인 범위는 알고 있는 경우가 많다.

#### 예시
- **제조업:** 양품 / 불량품 $\rightarrow$ $K \approx 2$
- **의료:** 정상 / 환자 $\rightarrow$ $K \approx 2$
- **금융:** 정상 거래 / 이상 거래

또한, 계층적 군집화의 **덴드로그램**이나 평가 지표(SSE, Silhouette)를 통해 $K$를 추정할 수도 있다.

---

## 4. K-means 알고리즘 절차

---
<img width="1488" height="1117" alt="image" src="https://github.com/user-attachments/assets/10652e82-fef9-473e-a2a3-948998350207" />

### Step 1️⃣  
**군집 개수 K 지정**

---

### Step 2️⃣  
**K개의 초기 중심(centroid)을 임의로 생성**
- 초기 위치는 랜덤하게 결정된다.

---

### Step 3️⃣  
**각 관측치를 가장 가까운 중심에 할당**
- 보통 **유클리드 거리**를 사용한다.
$$\text{cluster}(x_i) = \arg\min_k \|x_i - \mu_k\|$$

---

### Step 4️⃣  
**각 군집의 평균(mean) 계산**
$$\mu_k = \frac{1}{|C_k|} \sum_{x_i \in C_k} x_i$$
$\rightarrow$ 계산된 평균 지점으로 중심을 이동시킨다.

---

### Step 5️⃣  
**중심 이동 후 다시 군집 재할당**
- 이동한 중심을 기준으로 거리 계산 및 재배정을 수행한다.

---

### Step 6️⃣  
**중심이 더 이상 변하지 않을 때까지 반복**
이 과정을 **Iteration (반복)** 이라고 한다.



---

## 5. K-means 예제 흐름
<img width="1479" height="1057" alt="image" src="https://github.com/user-attachments/assets/a566d323-350a-4a51-a8dc-3e32db8a2ba1" />

### 예시 ① K = 2
1. 초기 중심 2개 랜덤 생성  
2. 거리 계산 후 군집 할당  
3. 평균 위치로 중심 이동  
4. 다시 군집 할당  
5. 중심이 더 이상 움직이지 않으면 종료

---

## 6. K-means 결과의 특징

| 구분 | 계층적 군집 | K-means |
| :--- | :--- | :--- |
| **결과** | 그림(Dendrogram) 해석 | 레이블(Label) 명확 |
| **주관성** | 있음 | 없음 |
| **군집 수** | 자동 해석 | 사전 지정 |

---

## 7. 초기 중심 문제 (Initialization Problem)
<img width="1411" height="973" alt="image" src="https://github.com/user-attachments/assets/9d11483d-bc56-4ced-a1bc-309e4a787453" />
<img width="1385" height="985" alt="image" src="https://github.com/user-attachments/assets/24b2417e-e708-43a3-a64d-9425bc1a23b3" />

> **초기 중심 위치에 따라 결과가 달라질 수 있음**

초기 중심이 실제 군집 중심 근처에 위치하면 이상적인 결과를 얻지만, 특정 군집에 몰려 있으면 잘못된 분리가 일어날 수 있다.

---

## 8. 초기 중심 문제 해결 방법
<img width="1453" height="482" alt="image" src="https://github.com/user-attachments/assets/acd83114-b4c5-48e3-8dc1-0170b5681f6b" />

1. **방법 1️⃣ 여러 번 반복 실행:** 랜덤 초기화 후 여러 번 수행하여 가장 자주 등장하거나 SSE가 낮은 결과를 선택한다.
2. **방법 2️⃣ 샘플링 + 계층적 군집화:** 일부 데이터로 덴드로그램을 그려 대략적 중심을 파악한 뒤 이를 초기값으로 사용한다.
3. **방법 3️⃣ 데이터 분포 활용:** 정규분포 등 데이터의 특성을 알고 있다면 평균값을 초기값으로 사용한다.

---

## 9. K-means의 한계점
<img width="1456" height="882" alt="image" src="https://github.com/user-attachments/assets/3b988cf7-83d2-42a4-9464-6c201e91cc37" />
<img width="1379" height="827" alt="image" src="https://github.com/user-attachments/assets/daff01e0-42f7-4f82-a441-182b724f2f67" />
<img width="1413" height="853" alt="image" src="https://github.com/user-attachments/assets/886070f9-7f36-4fd6-bf9e-91f7cc2d44b6" />

- **❌ 1. 군집 크기가 다른 경우:** 작은 군집이 큰 군집에 흡수되거나 무시될 수 있다.
- **❌ 2. 밀도가 다른 경우:** 밀도가 낮은 성긴 군집이 잘못 분류될 수 있다.
- **❌ 3. 지역적 패턴(Local Pattern):** 바나나 모양, 도넛 모양 등 비선형 구조는 유클리드 거리 기반의 K-means로 인식하기 어렵다.



---

## 10. 군집 개수(K) 선택 문제
<img width="1470" height="886" alt="image" src="https://github.com/user-attachments/assets/01b9a71e-a310-41eb-b1ef-1609d43a1044" />

객관적으로 $K$를 정하기 위해 **군집 평가 지표**가 사용된다.

---

## 11. SSE (Sum of Squared Errors)
<img width="1485" height="1053" alt="image" src="https://github.com/user-attachments/assets/16dd48cf-8548-41f3-bdef-ad7f7682ba95" />

각 군집 중심으로부터의 거리 제곱 합이다.
$$SSE = \sum_{k=1}^{K} \sum_{x_i \in C_k} \|x_i - \mu_k\|^2$$

- **특징:** $K$가 커질수록 무조건 감소한다.
- **Elbow Method:** 그래프가 급격히 꺾이는 지점(**elbow**)을 최적 $K$로 선택한다.



---

## 12. Silhouette 계수
<img width="1467" height="1111" alt="image" src="https://github.com/user-attachments/assets/061fa1e0-b673-4c2b-973d-47a29f37c221" />

군집 내 거리뿐만 아니라 군집 간 거리도 고려한 지표이다.

- $a(i)$: 같은 군집 내 평균 거리
- $b(i)$: 가장 가까운 다른 군집과의 평균 거리

### 실루엣 값
$$s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}$$
- **범위:** $-1 \le s(i) \le 1$ (1에 가까울수록 좋은 군집)

---

## 13. Silhouette 해석 팁
<img width="1499" height="1099" alt="image" src="https://github.com/user-attachments/assets/49cd8e07-512d-41a5-9509-7ef5758f14db" />

평균 Silhouette 값이 클수록 좋지만, 실무적으로는 **K=2**가 항상 가장 크게 나오는 경우가 많다. 따라서 가장 큰 값 대신 **두 번째로 큰 값(Second Best)** 을 선택하는 전략도 유효하다.

---

## 14. 정리

- **장점:** 빠르고 구현이 간단하며 대규모 데이터에 적합하다.
- **단점:** $K$를 미리 지정해야 하고, 원형 군집만 잘 탐색하며 이상치와 비선형 구조에 취약하다.

✅ **K-means는 가장 기본이지만 반드시 알아야 할 군집 알고리즘이다.**

---
📘 본 문서는 강의 내용을 수식과 핵심 개념 중심으로 재구성한 마크다운 정리 노트입니다.
