# Class Activation Map (CAM) & Grad-CAM 정리

---

## 1. 개요 (Explainable AI 관점)
<img width="1449" height="1055" alt="image" src="https://github.com/user-attachments/assets/338c04da-08a7-432d-bd62-e6d31335cb01" />

딥러닝 기반의 이미지 분류 모델, 특히 **CNN(Convolutional Neural Network)**은 매우 높은 분류 정확도를 보이지만, “왜 이런 예측을 했는가?”에 대한 설명이 어렵다는 한계를 가진다.

이를 해결하기 위해 등장한 것이 **설명 가능한 인공지능(XAI, Explainable AI)** 기법이며, 그 대표적인 방법이 **CAM**과 **Grad-CAM**이다. 이 기법들은 모델이 이미지의 어떤 영역을 근거로 특정 클래스를 예측했는지 시각적으로 보여준다.

- **CAM (2016, CVPR)**
- **Grad-CAM (2017, ICCV)**

---

## 2. CNN 구조 복습
<img width="1486" height="1133" alt="image" src="https://github.com/user-attachments/assets/81c192d0-f7bc-4b23-ad4c-65e02f16eaa7" />

### 2.1 Feature Extraction (특징 추출 단계)
입력 이미지가 들어오면 Convolution, ReLU, Pooling 과정을 반복하여 이미지의 모서리, 질감, 형태 정보를 담은 **Feature Map**을 생성한다.



### 2.2 Classification (분류 단계)
일반적인 CNN은 마지막 Feature Map을 **Flatten**하여 Fully Connected(FC) Layer에 입력한 뒤, Softmax를 통해 클래스 확률을 출력한다.

---

## 3. Class Activation Map (CAM)
<img width="1506" height="1105" alt="image" src="https://github.com/user-attachments/assets/5008bbcc-c452-4cb4-a424-918b93b0375b" />
<img width="1501" height="1051" alt="image" src="https://github.com/user-attachments/assets/1ddeff2a-5081-4cdf-84df-7f287134ff65" />

### 3.1 CAM의 핵심 아이디어
마지막 Convolution Layer의 Feature Map을 사용하여 해당 클래스 판별에 중요한 영역을 시각화한다.

### 3.2 CAM이 가능한 CNN 구조 조건
CAM을 사용하려면 구조적 제약이 따른다.
1. **Global Average Pooling (GAP)** 사용 필수
2. GAP 이후 곧바로 클래스를 출력하는 FC Layer 연결



### 3.3 Global Average Pooling (GAP)
<img width="1499" height="1067" alt="image" src="https://github.com/user-attachments/assets/a5aa2c4f-991f-4eda-b9ea-a44f6c3d8a38" />
<img width="1473" height="1050" alt="image" src="https://github.com/user-attachments/assets/d51162e5-8c9a-4fd6-adeb-330bb6890d88" />
<img width="1465" height="1075" alt="image" src="https://github.com/user-attachments/assets/9b979b95-f73f-492b-94ee-1b17173702a7" />

Feature Map의 모든 값을 평균 내어 하나의 스칼라 값으로 요약하는 연산이다.

### 3.4 CAM의 수식적 표현
<img width="1502" height="1076" alt="image" src="https://github.com/user-attachments/assets/87a0363f-9fe3-4b4d-8e0a-0672059c36b8" />
<img width="1490" height="1068" alt="image" src="https://github.com/user-attachments/assets/8e27c85a-bf42-408e-bb4a-881d9d788445" />
<img width="1499" height="1030" alt="image" src="https://github.com/user-attachments/assets/bfd092b1-f7ac-4b43-86b9-d2590639bfdc" />
<img width="1519" height="1067" alt="image" src="https://github.com/user-attachments/assets/d347fc2d-df78-46f8-a9e8-d3f0a314e6ee" />

마지막 Conv Layer의 $k$번째 Feature Map을 $A^k$라 할 때:

**1) Feature Map 평균 ($F^k$):**
$$F^k = \frac{1}{Z} \sum_i \sum_j A_{ij}^k$$
($Z$: 전체 픽셀 수)

**2) 클래스 점수 ($y^c$):**
$$y^c = \sum_k w_k^c F^k$$
($w_k^c$: 클래스 $c$에 대한 $k$번째 Feature Map 가중치)

**3) Class Activation Map ($M^c$):**
$$M^c(x, y) = \sum_k w_k^c A_k(x, y)$$

---

## 4. Grad-CAM (Gradient-weighted CAM)
<img width="1445" height="1059" alt="image" src="https://github.com/user-attachments/assets/f4eac8bc-f0d6-42c0-a2e7-af0b41a5b15d" />
<img width="1502" height="1034" alt="image" src="https://github.com/user-attachments/assets/9fd40432-3f1f-4000-8bdb-11378667795f" />
<img width="1479" height="1031" alt="image" src="https://github.com/user-attachments/assets/16fc097a-a9ad-407b-9b1c-1e1b9f00ba10" />
<img width="1521" height="1070" alt="image" src="https://github.com/user-attachments/assets/e53360be-ff23-43d9-9f0b-9e4609e94af2" />
<img width="1512" height="1104" alt="image" src="https://github.com/user-attachments/assets/ef57e35e-6fc2-402f-b427-0decb900b22a" />
<img width="1509" height="1087" alt="image" src="https://github.com/user-attachments/assets/14753077-2e27-4779-9740-4ca54e899b6d" />

### 4.1 Grad-CAM의 핵심 아이디어
**Gradient(미분)**를 이용하여 각 Feature Map이 특정 클래스 출력에 미치는 영향력을 계산한다. 

### 4.2 Grad-CAM의 장점
- CNN 구조 변경 불필요 (GAP 없어도 됨)
- 모델 재학습 불필요
- 거의 모든 CNN 기반 모델에 적용 가능

### 4.3 Grad-CAM 가중치 정의
특정 클래스 $c$의 출력값 $y^c$를 Feature Map $A^k$에 대해 미분하여 가중치 $\alpha_k^c$를 구한다.
$$\alpha_k^c = \frac{1}{Z} \sum_i \sum_j \frac{\partial y^c}{\partial A_{ij}^k}$$

### 4.4 Grad-CAM 맵 생성
$$L_{\text{Grad-CAM}}^c = \text{ReLU}\left(\sum_k \alpha_k^c A^k \right)$$
- **ReLU 적용 이유:** 클래스 결정에 **긍정적 기여**를 하는 부분만 시각화하기 위함이다.

[Image showing the process of generating a Grad-CAM heatmap from feature maps and gradients]

---

## 5. CAM vs Grad-CAM 비교

| 항목 | CAM | Grad-CAM |
| :--- | :--- | :--- |
| **CNN 구조 변경** | 필요 | 불필요 |
| **GAP 필수 여부** | 필수 ($O$) | 불필요 ($X$) |
| **재학습 여부** | 필요 | 불필요 |
| **가중치 결정** | 학습된 FC Weight | Gradient (미분값) |

---

## 6. 실제 예제 해석
<img width="1512" height="1070" alt="image" src="https://github.com/user-attachments/assets/ae9dc10c-9c2f-4293-bc39-a22d453d6492" />
<img width="1497" height="1069" alt="image" src="https://github.com/user-attachments/assets/a30219ad-8be8-4b73-8d58-993ce05772bb" />

- **강아지 분류:** 얼굴, 눈, 코 주변이 붉게 강조되어 모델이 얼굴 특징을 주로 참고했음을 확인.
- **의료 영상 (X-ray):** 병변이나 수술 부위가 강조되어 모델이 의학적으로 유의미한 영역을 보고 있는지 검증 가능.
- **데이터 편향 발견:** 인물 분류 시 인물 자체가 아닌 넥타이 색상 등을 강조한다면 모델이 잘못된 단서를 학습했음을 파악할 수 있음.



---

## 7. 정리
- CNN은 성능이 좋지만 **설명력이 부족**한 블랙박스 모델이다.
- CAM과 Grad-CAM은 모델의 판단 근거를 시각적으로 제공하여 **신뢰성**을 높인다.
- 특히 **Grad-CAM**은 범용성이 높아 실무와 연구에서 널리 사용되는 XAI의 핵심 도구이다.

📘 본 문서는 강의 내용을 수식과 핵심 개념 중심으로 재구성한 마크다운 정리 노트입니다.
