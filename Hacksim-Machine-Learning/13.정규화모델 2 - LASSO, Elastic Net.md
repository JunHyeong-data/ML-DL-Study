# 정규화 모델 (2)
## LASSO, Elastic Net, 그리고 확장 정규화 기법

---

## 1. 강의 개요
이번 강의에서는 정규화 모델 중
- **LASSO (Least Absolute Shrinkage and Selection Operator)**
- **Elastic Net**
을 중심으로 설명하고, 그 이후 확장된 정규화 방법들을 간단히 소개한다.

본 강의는 **정규화 모델 1강(배경 및 기본 개념)**을 기반으로 하므로, 해당 강의를 먼저 수강한 후 듣는 것이 이해에 도움이 된다.

---

## 2. LASSO 모델 개요
<img width="1438" height="1095" alt="image" src="https://github.com/user-attachments/assets/7ce72dce-943e-49d2-b026-1d107f0019ab" />

### 2.1 LASSO의 정의
LASSO는 **Least Absolute Shrinkage and Selection Operator**의 약자로, 회귀 계수에 **L1 노름(절댓값 합)** 제약을 가하는 정규화 기법이다.

LASSO의 핵심 특징은 다음 두 가지이다.
1. **Shrinkage (계수 축소)**
2. **Variable Selection (변수 선택)**

즉, 계수 크기를 줄이면서 중요하지 않은 변수의 계수를 **정확히 0으로 만든다.**
👉 자동 변수 선택 기능을 가진 회귀 모델이다.

---

## 3. LASSO의 수식 표현

### 3.1 제약식 형태 (Constrained form)
$$
\min_{\boldsymbol{\beta}} \sum_{i=1}^{n}(y_i - \mathbf{x}_i^\top \boldsymbol{\beta})^2 \quad \text{subject to} \quad \sum_{j=1}^{p} |\beta_j| \le t
$$
- $t$: 제약의 강도를 조절하는 상수

### 3.2 패널티 형태 (Penalized form)
위 문제는 다음과 동치이다.

$$
\min_{\boldsymbol{\beta}} \sum_{i=1}^{n}(y_i - \mathbf{x}_i^\top \boldsymbol{\beta})^2 + \lambda \sum_{j=1}^{p} |\beta_j|
$$
- $\lambda$: **정규화 파라미터 (Regularization parameter)**

### 3.3 Ridge Regression과의 차이

| 모델 | 패널티 | 특징 |
| :--- | :--- | :--- |
| **Ridge** | $\sum \beta_j^2$ ($L2$ 노름) | 계수를 0에 가깝게 축소 (0은 아님) |
| **LASSO** | $\sum |\beta_j|$ ($L1$ 노름) | 계수를 **정확히 0**으로 만듦 (변수 선택) |

👉 **차이는 “제곱” vs “절댓값”**

---

## 4. LASSO의 기하학적 해석
<img width="1402" height="987" alt="image" src="https://github.com/user-attachments/assets/c1a8591c-c667-4abb-815d-2a34dbdeef77" />

### 4.1 제약 영역의 형태
- **Ridge:** 원(circle)
- **LASSO:** 마름모(diamond)



LASSO 제약 영역은 **꼭짓점(corner)**을 가지며, 이 꼭짓점에서 최적해가 결정될 가능성이 매우 크다.
👉 꼭짓점에서는 $\beta_j = 0$이 되는 경우가 자연스럽게 발생한다.

### 4.2 변수 선택 메커니즘
- 어떤 $\beta_j = 0$ $\rightarrow$ 해당 변수는 **예측에 기여하지 않음**
- $\beta_j \neq 0$ $\rightarrow$ 중요한 변수로 선택됨
👉 이것이 LASSO가 **변수 선택 모델**인 이유이다.

---

## 5. LASSO 패널티 함수의 형태
- **LASSO 패널티:** $|\beta|$
그래프 형태는 **V자 형태 (비미분 가능)**이다.
📌 Ridge는 포물선 $\rightarrow$ 미분 가능
📌 LASSO는 절댓값 $\rightarrow$ 0에서 미분 불가능

---

## 6. 최적화 관점에서의 특징
<img width="1493" height="1026" alt="image" src="https://github.com/user-attachments/assets/a603d68b-c4f3-424b-ac34-a8f5b9a84cea" />

### 6.1 해석적 해 (Closed-form solution)
- **Ridge:** 존재 (미분 가능)
- **LASSO:** **존재하지 않음**

👉 LASSO는 **수치 최적화(Numerical Optimization)**가 필요하다.
대표적인 알고리즘:
- Coordinate Descent
- LARS (Least Angle Regression)
- Subgradient methods

---

## 7. 정규화 파라미터 ($\lambda$)의 역할
<img width="789" height="897" alt="image" src="https://github.com/user-attachments/assets/2b9e9f39-d56a-46b7-94a7-ab68bc3e24ac" />

### 7.1 극단적인 경우
- $\lambda = 0$: 최소제곱법(OLS)과 동일
- $\lambda \to \infty$: 모든 $\beta_j = 0$

### 7.2 Bias–Variance Tradeoff

| $\lambda$ 크기 | 효과 |
| :--- | :--- |
| **큼** | 단순 모델, 변수 적음, 언더피팅(Underfitting) 위험 |
| **작음** | 복잡한 모델, 변수 많음, 오버피팅(Overfitting) 위험 |

👉 $\lambda$ 선택은 **모델 복잡도 조절 문제**이다.

---

## 8. LASSO 계수 경로 (Solution Path)
<img width="1496" height="1066" alt="image" src="https://github.com/user-attachments/assets/f589da75-3ec7-4681-90e0-66bd20e34a31" />

- $\lambda$ 증가 $\rightarrow$ 계수들이 점점 0으로 수렴
- 특정 시점에서 계수가 정확히 0이 됨
- 변수들이 순차적으로 제거됨
👉 **Sparse model** 형성



---

## 9. LASSO의 안정성 (Robustness)
<img width="1503" height="927" alt="image" src="https://github.com/user-attachments/assets/b7dfc753-fbcd-4008-9405-2f83afbd8932" />

### 9.1 낮은 상관관계의 경우
- 데이터가 조금 변해도 선택되는 변수와 계수 변화가 작음
👉 비교적 안정적이다.

### 9.2 높은 상관관계의 경우 (문제점)
- 변수 간 상관이 높으면 데이터 변화에 따라 선택되는 변수가 달라짐
👉 **불안정한 변수 선택**이 발생한다.

---

## 10. Elastic Net 모델
<img width="1446" height="1080" alt="image" src="https://github.com/user-attachments/assets/a396540e-9353-4bdb-93ae-aef87f603442" />

### 10.1 Elastic Net의 등장 배경
- **LASSO:** 변수 선택 가능
- **Ridge:** 상관 변수 처리에 강함
👉 두 모델의 장점을 결합하였다.

### 10.2 Elastic Net 수식
$$
\min_{\boldsymbol{\beta}} \sum_{i=1}^{n}(y_i - \mathbf{x}_i^\top \boldsymbol{\beta})^2 + \lambda_1 \sum_{j=1}^{p} |\beta_j| + \lambda_2 \sum_{j=1}^{p} \beta_j^2
$$
- $\lambda_1$: LASSO 성분 ($L1$)
- $\lambda_2$: Ridge 성분 ($L2$)

### 10.3 Elastic Net의 장점
<img width="1384" height="938" alt="image" src="https://github.com/user-attachments/assets/33323124-e66c-4da0-944f-788ea3637475" />

- 상관관계 높은 변수들을 **그룹으로 선택**
- LASSO의 불안정성 개선
- 변수 선택 + 안정성 확보
👉 **Grouping Effect**

---

## 11. Elastic Net 제약 영역
- **Ridge:** 원
- **LASSO:** 마름모
- **Elastic Net:** 그 중간 형태 (모서리는 유지하면서 부드러움 증가)



---

## 12. ($\lambda_1, \lambda_2$) 선택
- 두 개의 하이퍼파라미터가 필요하다.
- 일반적으로 **Grid Search + Cross Validation**을 사용하여 최적의 조합을 찾는다.

---

## 13. 확장 정규화 모델 (간단 소개)
<img width="1451" height="1038" alt="image" src="https://github.com/user-attachments/assets/6731c9ac-ac59-4a04-955b-1196da15db72" />

### 13.1 Fused LASSO
<img width="1494" height="986" alt="image" src="https://github.com/user-attachments/assets/b240e8a1-2ca1-4a4c-bb89-e118b29a7174" />

- 인접 변수 간 계수 차이 최소화
- 신호 데이터, 스펙트럼 데이터에 적합

### 13.2 Group LASSO
<img width="1464" height="1041" alt="image" src="https://github.com/user-attachments/assets/d4c260c4-5777-4030-9a58-ac72e6fee3fa" />

- 사용자가 정의한 변수 그룹 단위로 선택 수행

### 13.3 Sparse Group LASSO
<img width="1509" height="1078" alt="image" src="https://github.com/user-attachments/assets/d12abe81-cc06-463b-b7fe-ee4193666386" />

- 그룹 선택 + 그룹 내 개별 변수 선택

### 13.4 Non-convex Penalty
<img width="1474" height="775" alt="image" src="https://github.com/user-attachments/assets/e7032988-83c2-47a0-978b-67629b953139" />

- SCAD, MCP 등
- 큰 계수는 덜 줄이고, 작은 계수는 강하게 제거하여 Bias 문제 개선

---

## 14. 강의 정리
- **LASSO:** 변수 선택 가능 ($L1$)
- **Ridge:** 안정성 우수 ($L2$)
- **Elastic Net:** 둘의 장점 결합
- **확장 모델:** 데이터의 구조적 정보 반영

👉 **정규화는 단순한 패널티가 아니라 “모델 설계”의 문제이다.**
