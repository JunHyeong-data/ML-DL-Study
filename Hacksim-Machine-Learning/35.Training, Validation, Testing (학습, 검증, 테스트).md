# Training / Validation / Test 데이터 개념 정리

---

## 1. 개요

머신러닝과 인공지능 모델링 과정은 크게 다음 **세 단계**로 나눌 수 있다.

1. **학습 (Training)**
2. **검증 (Validation)**
3. **테스트 (Testing)**



---

## 2. 데이터 분할의 기본 원칙
<img width="1433" height="1062" alt="image" src="https://github.com/user-attachments/assets/2c2dad3e-c82e-485e-8b1f-b5860864f7e4" />

### ✅ 가장 중요한 원칙
- **학습 / 검증 / 테스트 데이터는 절대 서로 겹치면 안 된다.**
- 하나의 관측치는 오직 하나의 데이터셋에만 속해야 한다.

---

## 3. 데이터 분할 비율
정해진 정답은 없지만 일반적으로 다음 비율을 많이 사용한다.
- **6 : 2 : 2**
- **7 : 2 : 1**

학습 데이터는 모델을 만드는 데 사용되므로 **가장 많은 비중**을 차지한다.

---
<img width="1497" height="1057" alt="image" src="https://github.com/user-attachments/assets/d5501dc9-cdcc-45fc-8915-736e133ebb40" />

## 4. 학습 데이터 (Training Data)

### 정의
- 모델을 구축하는 데 사용하는 데이터이다.

### 역할
- 모델이 데이터의 패턴을 학습하고 파라미터(Parameter)가 업데이트된다.
- 예시: 신경망 모델에서의 **가중치(Weight)**는 경사하강법을 통해 로스(Loss)를 줄이는 방향으로 업데이트된다.

👉 **가중치 업데이트는 오직 학습 데이터로만 수행된다.**

---

## 5. 테스트 데이터 (Test Data)

### 정의
- 학습이 완료된 모델의 성능을 평가하기 위한 데이터이다.

### 특징
- 학습 과정에서는 **절대 사용하면 안 된다.**
- “존재하지 않는 미래 데이터”처럼 취급해야 한다.

### 평가 방식
- 예측값 $\hat{y}$와 실제값 $y$를 비교하여 성능 지표(Accuracy, RMSE, MAE 등)를 계산한다.

---

## 6. 검증 데이터 (Validation Data)
<img width="1417" height="603" alt="image" src="https://github.com/user-attachments/assets/b7ed5a83-fcb3-4621-9105-fdc5daa1b05d" />

### 핵심 역할
1. **모델 성능 사전 점검**
2. **최적의 모델 선택**
3. **하이퍼파라미터 튜닝**

---
<img width="1407" height="913" alt="image" src="https://github.com/user-attachments/assets/d600aaa9-ff11-4228-9afb-c0d1ceb2f3ca" />

## 7. 파라미터 vs 하이퍼파라미터

### 🔹 파라미터 (Parameter)
- 학습 과정 중 알고리즘이 스스로 결정하여 자동으로 업데이트되는 값이다.
- 예시: 신경망의 가중치(Weight), 결정트리의 분할 기준값 등

### 🔹 하이퍼파라미터 (Hyperparameter)
- 사용자가 직접 정해야 하며, 학습 중 자동으로 업데이트되지 않는 값이다.
- 예시: 은닉층 개수, 배치 사이즈, 학습률(Learning rate), 결정트리의 최대 깊이($max\_depth$), KNN의 $K$ 값 등

---

## 8. 학습 · 검증 · 테스트 관계 요약

| 구분 | 사용 목적 |
| :--- | :--- |
| **학습 데이터** | 가중치(파라미터) 업데이트 |
| **검증 데이터** | 모델 선택, 하이퍼파라미터 튜닝 |
| **테스트 데이터** | 최종 성능 평가 |

---

## 9. 시계열 데이터 주의사항
- **비시계열 데이터:** 순서가 중요하지 않아 **셔플(Shuffle)**이 가능하다.
- **시계열 데이터:** 시간 순서가 매우 중요하므로 셔플을 금지하며, 과거 데이터를 학습에, 미래 데이터를 테스트에 사용한다.



---

## 10. 스케일링 시 주의사항 ⭐
<img width="1455" height="939" alt="image" src="https://github.com/user-attachments/assets/9efd3266-6b6e-4a6d-8297-69cebfb6b698" />

검증 및 테스트 데이터를 스케일링할 때는 **반드시 학습 데이터의 최대·최소값(또는 평균·표준편차)만 사용**해야 한다. 
- **이유:** 실제 환경에서는 미래 데이터의 통계를 미리 알 수 없으며, 이를 어길 시 데이터 누수(Data Leakage)가 발생한다.

---

## 11. 최적의 모델 선택 (Validation Loss)
<img width="1487" height="911" alt="image" src="https://github.com/user-attachments/assets/b8e424eb-c52b-4133-9e32-af74389152ce" />

### 일반적인 학습 패턴
- **Training Loss:** 학습이 진행될수록 계속 감소한다.
- **Validation Loss:** 감소하다가 어느 시점부터 다시 증가하기 시작한다.



👉 **최적의 모델**은 Training loss가 가장 작은 모델이 아니라, **Validation loss가 최소가 되는 시점**의 파라미터를 가진 모델이다.

---

## 12. Early Stopping
<img width="1461" height="921" alt="image" src="https://github.com/user-attachments/assets/42d7d974-4298-4a45-8c3e-92093c49cfcc" />

Validation loss가 더 이상 감소하지 않을 때 학습을 조기에 종료하여 과적합을 방지하는 기법을 **Early Stopping**이라 한다.

---

## 13. 하이퍼파라미터 선택 과정
<img width="1490" height="973" alt="image" src="https://github.com/user-attachments/assets/73469711-479d-4d8b-9608-0d2785ba708e" />

1. 여러 하이퍼파라미터 조합 설정
2. 각 조합마다 모델 학습 후 Validation loss 비교
3. 가장 작은 validation loss를 가진 조합을 최종 선택

---

## 14. K-Fold Cross Validation
<img width="1507" height="950" alt="image" src="https://github.com/user-attachments/assets/8ffe15c3-9b6c-4adc-96ba-b85f7990359b" />

데이터를 $K$개로 분할하여 검증 위치를 바꿔가며 $K$번 반복 학습하는 방법이다.
- 한 번의 분할로 발생할 수 있는 과적합을 방지한다.
- 각 Fold의 성능 평균을 모델의 최종 성능으로 간주한다.



---

## 15. 전체 흐름 요약
1. **데이터 분할:** Train / Validation / Test
2. **학습:** 가중치 업데이트 (Train 기준)
3. **모델 선택:** Validation loss 최소 지점 탐색
4. **하이퍼파라미터 튜닝:** Validation 성능 기준 최적화
5. **최종 평가:** Test data로 단 한 번 최종 성능 측정

✅ **Validation loss 최소 지점이 최적 모델이며, Test 데이터는 마지막에 단 한 번만 사용한다.**

---

# Training / Validation / Testing 데이터 개념 정리 (실전 예제 포함)

---

## 1. 실제 모델 예제로 이해하기
이번에는 의사결정나무, 인공신경망, 시계열 모델 등 실제 예제를 통해 **학습(Training) · 검증(Validation) · 테스트(Testing)** 개념을 정리한다.

---

## 2. 의사결정나무(Decision Tree) 예제
<img width="1529" height="1049" alt="image" src="https://github.com/user-attachments/assets/f3f5d763-c671-4406-87f3-f46407a30832" />

### 📌 문제 설정
- **전체 데이터:** 10,000개 (이진 분류 문제)
- **입력 변수:** 고객 나이, 연수입, 기타 금융 변수
- **출력 변수:** 채무 불이행 여부 (Yes / No)

### 📌 데이터 분할 (6 : 2 : 2)
- **학습 데이터:** 6,000개
- **검증 데이터:** 2,000개
- **테스트 데이터:** 2,000개

---

## 3. 학습 + 검증 단계
- **사용 데이터:** 학습 데이터, 검증 데이터
- **목적:** 최적의 모델 선택 및 과적합(Overfitting) 방지

---

## 4. 의사결정나무에서의 학습 과정
의사결정나무는 가중치를 업데이트하는 대신 **하이퍼파라미터**를 조절하여 모델을 최적화한다.
- **주요 하이퍼파라미터:** 최대 깊이(max depth), 터미널 노드 수 등

### 📉 로스 곡선 해석
- **특징:** 모델이 깊어질수록 학습 에러는 계속 감소하지만, 검증 에러는 어느 순간부터 다시 증가한다.



### ✅ 최종 모델 선택 기준
> **검증 에러가 최소가 되는 시점의 모델**
- 트레이닝 에러가 0이 되는 모델은 과적합된 모델이므로 선택하지 않는다.

---

## 5. 테스트 단계
- **특징:** 학습 과정에서 절대 사용하지 않으며, 모든 학습이 끝난 후에만 단 한 번 사용한다.
- **방법:** 최종 모델에 테스트 데이터를 입력하여 예측값 $\hat{y}$를 얻고, 실제 $y$와 비교하여 **일반화 성능(정확도 등)**을 평가한다.

---

## 6. 인공신경망(CNN) 예제
<img width="1501" height="1079" alt="image" src="https://github.com/user-attachments/assets/258d6f84-9ce4-4f6d-9047-b3e3ab7b0c59" />

### 📌 문제 설정
- **전체 데이터:** 100,000개 (강아지, 고양이, 토끼 다중 분류)
- **입력:** 이미지 / **출력:** 클래스 레이블

### 📌 데이터 분할
- **학습:** 60,000 / **검증:** 20,000 / **테스트:** 20,000

---

## 7. 신경망에서의 학습 과정
- **학습 데이터:** 가중치(Weight) 업데이트에 직접 사용된다.
- **검증 데이터:** Validation loss가 최소가 되는 **Epoch** 시점의 가중치를 최적 모델로 선택한다.



---

## 8. 셔플링과 층화 샘플링 (Stratified Sampling)
클래스 비율이 불균형할 경우(예: 강아지 50%, 고양이 30%, 토끼 20%), 무작위 추출 시 특정 클래스가 편향될 수 있다.
- **해결 방법:** 학습/검증/테스트 데이터셋 모두에서 **클래스 비율을 동일하게 유지**하도록 샘플링한다.

---

## 9. 시계열 데이터의 경우 (중요)
- **⚠ 주의사항:** **셔플링 절대 금지.** 시간 순서 자체가 정보이기 때문이다.
- **분할 방식:** 과거 데이터를 학습에, 중간 데이터를 검증에, 가장 최신(미래) 데이터를 테스트에 배치한다.



---

## 10. 시계열 모델 예제 (RNN)
<img width="1502" height="1098" alt="image" src="https://github.com/user-attachments/assets/97e1c0a2-d110-47de-b249-b83d26a99fc7" />

- **입력:** 제조 공정 센서 데이터 / **출력:** 제품 이상 여부
- **윈도우(Window) 개념:** 단일 시점이 아닌 여러 시점을 묶어 하나의 입력으로 사용한다.
  - 예: Window size = 3 $\implies [t_1, t_2, t_3] \rightarrow \text{Input 1}$

---

## 11. 테스트의 진짜 의미
테스트 데이터는 사실상 **미래 데이터의 대리물**이다. 
- 테스트 에러(Testing error/loss) 또는 **일반화 오차(Generalization error)**가 작을수록 새로운 데이터에도 잘 작동할 가능성이 높다.

---

## 12. 핵심 요약

| 단계 | 역할 |
| :--- | :--- |
| **Training** | 가중치 업데이트 및 모델 패턴 학습 |
| **Validation** | 하이퍼파라미터 튜닝 및 최적 모델 결정(과적합 방지) |
| **Testing** | 최종 성능 평가 및 일반화 능력 판단 |

### ✅ 정리 한 문장
> **학습과 검증은 모델을 만들기 위한 과정이고, 테스트는 만들어진 모델을 평가하기 위한 과정이다.**

---
📘 본 문서는 강의 내용을 수식과 핵심 개념 중심으로 재구성한 마크다운 정리 노트입니다.
