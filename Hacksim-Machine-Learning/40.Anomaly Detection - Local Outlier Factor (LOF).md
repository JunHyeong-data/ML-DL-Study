# Local Outlier Factor (LOF) 강의 정리
<img width="1195" height="845" alt="image" src="https://github.com/user-attachments/assets/550671c8-1ceb-4ca3-8ac8-435e0770c68f" />
<img width="1180" height="840" alt="image" src="https://github.com/user-attachments/assets/d0b3e153-c28b-4035-95ab-dc6aebd02a6f" />
<img width="1195" height="842" alt="image" src="https://github.com/user-attachments/assets/a28f5603-5f15-4b8e-b77e-79ee28462872" />

---

## 1. 문제 설정: 이상치 탐지(Anomaly Detection)

* **목표**: 주어진 데이터에서 정상(normal)과 이상(outlier)을 구분
* **직관적 가정**
  * 정상 데이터는 서로 **밀집**되어 있음
  * 이상치는 주변 데이터로부터 **고립**되어 있음
* **결과적으로 각 관측치마다 이상치 점수(score)를 계산**
  * 점수 $\uparrow$ → 이상치 가능성 $\uparrow$
  * 점수 $\downarrow$ → 정상 가능성 $\downarrow$

---

## 2. 거리 기반 접근 vs 확률 분포 기반 접근

### 확률 분포 기반
* 특정 분포(정규분포 등)를 가정
* 파라미터 추정 필요
* 가정이 틀리면 성능 저하

### 거리 기반 (LOF)
* 분포 가정 ❌
* **정의 + 알고리즘적 절차** 중심
* 직관적이지만 계산량이 큼

---

## 3. 핵심 정의 ①: k-distance
<img width="1181" height="848" alt="image" src="https://github.com/user-attachments/assets/e452acac-9ec3-44b6-8809-0adc62d9e050" />
<img width="1183" height="859" alt="image" src="https://github.com/user-attachments/assets/d39f7f58-d679-4e4d-8a00-feea68597253" />
<img width="1186" height="855" alt="image" src="https://github.com/user-attachments/assets/11ca911f-cfb2-4b5c-883e-4b9da190f816" />

### 정의
관측치 $p$에 대해:
* 자기 자신을 제외한 다른 모든 점과의 거리 계산
* **k번째로 가까운 이웃까지의 거리**를 **$k\text{-distance}(p)$**라고 정의

### 주의사항 (동률 거리)
* 동일한 거리 값이 여러 개 존재할 수 있음
* 이 경우에도 정의에 따라 **k번째에 해당하는 거리 값**을 사용

---

## 4. 핵심 정의 ②: k-distance neighborhood
<img width="1187" height="843" alt="image" src="https://github.com/user-attachments/assets/ee200dca-2265-42b4-b943-9975c56f6475" />
<img width="1192" height="856" alt="image" src="https://github.com/user-attachments/assets/6343415b-63f6-405b-b4c4-06b5f3894342" />
<img width="1186" height="851" alt="image" src="https://github.com/user-attachments/assets/909520dc-b8d9-49ad-9a37-72cfc67e53e3" />

### 정의
> $N_k(p)$: $k\text{-distance}(p)$ 이내($\le$)에 존재하는 **모든 이웃의 집합**

* 개수는 항상 $k$와 같지 않을 수 있음
* 이유: 거리 **동률(tie)** 때문

### 표기
* $|N_k(p)| = n_k(p)$

---

## 5. 핵심 정의 ③: Reachability Distance
<img width="1182" height="857" alt="image" src="https://github.com/user-attachments/assets/7dc3eed9-0e7f-44a9-b26f-2bcfa023aa8e" />
<img width="1185" height="852" alt="image" src="https://github.com/user-attachments/assets/0139f82c-967d-42d5-962e-2d3df7195b2d" />
<img width="1180" height="868" alt="image" src="https://github.com/user-attachments/assets/9d6ae9c9-4ce7-417e-acc9-5edece100a5f" />

### 정의
관측치 $p$와 이웃 $o$에 대해:
$$\text{reach-dist}_k(p,o) = \max\big(k\text{-distance}(o), d(p,o)\big)$$

### 해석
* 단순 거리 $d(p,o)$를 그대로 쓰지 않음
* 이웃 $o$의 **지역적 밀도 기준**을 반영

### 직관
* 정상 밀집 지역 $\rightarrow$ reach-dist 작음
* 이상치 $\rightarrow$ reach-dist 큼



---

## 6. 핵심 정의 ④: Local Reachability Density (LRD)
<img width="1191" height="853" alt="image" src="https://github.com/user-attachments/assets/7bbdcd7f-4afa-4f67-8194-73b30cd2e0b8" />
<img width="1181" height="859" alt="image" src="https://github.com/user-attachments/assets/f4ac25f7-d990-4862-a486-9e7ab8e73ab6" />

### 정의
$$\text{lrd}_k(p) = \frac{|N_k(p)|}{\sum_{o \in N_k(p)} \text{reach-dist}_k(p,o)}$$

### 해석
* **도달 가능 거리의 역수 개념**
* 값이 클수록 $\rightarrow$ 주변이 빽빽 (정상)
* 값이 작을수록 $\rightarrow$ 주변이 듬성듬성 (이상)

---

## 7. 최종 정의: Local Outlier Factor (LOF)
<img width="1190" height="857" alt="image" src="https://github.com/user-attachments/assets/84a35997-8321-4e3c-9645-479350ee3704" />
<img width="1188" height="865" alt="image" src="https://github.com/user-attachments/assets/d42ec04a-49cb-4076-b459-44573b35dbff" />
<img width="1202" height="863" alt="image" src="https://github.com/user-attachments/assets/27a86de2-24e3-4b55-b3c7-cc62bc26c6fb" />
<img width="1187" height="858" alt="image" src="https://github.com/user-attachments/assets/bea5fed0-839a-4380-a8c0-b70d58900301" />

### 정의
$$\text{LOF}_k(p) = \frac{1}{|N_k(p)|} \sum_{o \in N_k(p)} \frac{\text{lrd}_k(o)}{\text{lrd}_k(p)}$$

### 해석
* **내 밀도 vs 이웃들의 평균 밀도** 비교

[Image illustrating the LOF ratio comparison between a point's density and its neighbors' densities]

### 값의 의미
* $\text{LOF} \approx 1 \rightarrow$ 정상
* $\text{LOF} > 1 \rightarrow$ 이상치
* 값이 클수록 이상치 가능성 $\uparrow$

---

## 8. 다양한 경우 해석

- **(1) 정상 + 밀집:** $lrd(p)$ 큼. 이웃 $lrd$와 비슷 $\rightarrow$ $LOF \approx 1$
- **(2) 고립된 이상치:** $lrd(p)$ 작음. 이웃 $lrd$ 큼 $\rightarrow$ $LOF \gg 1$
- **(3) 성긴 군집 내부:** 군집 자체는 정상. 밀도 낮으나 이웃과 비슷 $\rightarrow$ $LOF \approx 1$
- **(4) 소수 점만 있는 군집:** 군집 내부에 점이 적고 상대적으로 고립 $\rightarrow$ $LOF$ 크게 나올 수 있음

---

## 9. LOF의 한계점 및 연구 아이디어
<img width="1192" height="706" alt="image" src="https://github.com/user-attachments/assets/b1a6a8a9-4a19-4446-b945-62c4f743a981" />

### 1️⃣ k 선택 문제
* $k$에 따라 결과 변화. 너무 작으면 불안정하고 너무 크면 지역성 상실
* 👉 **실험적으로 안정 구간 탐색 필요**

### 2️⃣ 스케일 문제
* $LOF$는 $[0, 1]$ 범위 아님. 데이터셋마다 해석 기준 다름
* 👉 **연구 아이디어:** Normalized LOF, Scaled LOF

### 3️⃣ Threshold 결정 문제
* "LOF가 얼마 이상이면 이상치?"에 대한 명확한 기준 없음
* **대안:** 상위 $n\%$를 이상치로 정의하거나 사전 정의된 비율 사용

### 4️⃣ 계산 복잡도
* 모든 점 쌍 거리 계산 필요 ($O(n^2)$)
* 👉 **개선 방법:** 근사 kNN, 샘플링, 차원 축소 후 적용

---

## 10. 정리

* LOF는 **직관적이고 강력한 거리 기반 이상치 탐지 기법**
* 단, $k$ 선택 / 스케일 / 계산 복잡도 문제가 존재하여 연구 주제로 확장 가능성이 큼

> ✔ 기존 방법을 정확히 이해하는 것이 연구의 출발점

---

📘 본 문서는 강의 내용을 수식과 핵심 개념 중심으로 재구성한 마크다운 정리 노트입니다.
